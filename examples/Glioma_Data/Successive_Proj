#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jul 25 15:36:07 2018

@author: nicolasguigui
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jun  6 15:36:13 2018

@author: nicolasguigui
"""

import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import sys
sys.path.append('/Users/nicolasguigui/Documents/CEA')
from projection import linear_proj_l1l2
from scipy import sparse
from scipy.io import mmread

from sklearn.preprocessing import StandardScaler
import parsimony.functions.penalties as penalties
import parsimony.utils.consts as consts

def cor(X1,X2,Y,x,z,t):
    xtXt = np.dot(x.T, X1.T) 
    ztZt = np.dot(z.T, X2.T)
    Yy = np.dot(Y, t)
    cor1 = np.dot(xtXt, Yy)
    cor1 /= np.linalg.norm(xtXt) * np.linalg.norm(Yy)
    cor2 = np.dot(ztZt, Yy)
    cor2 /= np.linalg.norm(ztZt) * np.linalg.norm(Yy)
    return cor1[0,0] + cor2[0,0]

data_dir = "/Users/nicolasguigui/gits/pylearn-parsimony/examples/Glioma_Data/"    
data = pd.read_csv(data_dir + 'Data_Subset.csv').drop('Unnamed: 0', axis=1)
X2 = data.loc[:,data.columns.str.startswith('CGH')].values
y = data.loc[:,data.columns[-3:]].values
X1 = data.loc[:,data.columns.str.startswith('GE')].values

adj = mmread(data_dir + 'Kegg_Graph.txt').tocsr()
L = sparse.csgraph.laplacian(adj)


std1 = StandardScaler()
std2 = StandardScaler()
X1 = std1.fit_transform(X1)
X2 = std2.fit_transform(X2)
X2 /= np.sqrt(X2.shape[1])
X1 /= np.sqrt(X1.shape[1])

l1 = 0.2 * np.sqrt(X1.shape[1])
l2 = 0.5 * np.sqrt(X2.shape[1])
g1 = 1e-2

constraint1_L1 = penalties.L1(c=l1)
constraint2_L1 = penalties.L1(c=l2)
constraint1_L2 = penalties.L2(c=1.0)
constraint2_L2 = penalties.L2(c=1.0)
constraint3 = penalties.L2(c=1.0)

y_ = np.copy(y)
# Standardise the dummy matrix.
_, labels = np.where(y == 1)

y_ -= np.mean(y_, axis=0)
y_ /= np.std(y_, axis=0)

V_1,S_1,U_1 = np.linalg.svd(X1.T,full_matrices=0)
V_2,S_2,U_2 = np.linalg.svd(X2.T,full_matrices=0)
V_3,S_3,U_3 = np.linalg.svd(y_.T,full_matrices=0)


prox1 = [constraint1_L1,constraint1_L2]
prox2 = [constraint2_L1,constraint2_L2]
prox3 = [constraint3]

XtY = np.dot(X1.T,y_) / (X1.shape[0] - 1.0)
ZtY = np.dot(X2.T,y_) / (X1.shape[0] - 1.0)

step_0 = 0.005
step_1 = 0.005
step_2 = 0.005

num_iter = [0,0,0]
#### Without ISTA steps

x = V_1.T[0,:].reshape((X1.shape[1],1))
z = V_2.T[0,:].reshape((X2.shape[1],1))
t = np.array([-1/np.sqrt(2), 1/np.sqrt(2), 0]).reshape((3,1))

block_iter = 0
eps = 5e-14
XtYy = np.dot(XtY,t)
ZtYy = np.dot(ZtY,t)

def fval(x,z,y,g1):
    return (np.dot(x.T,XtYy) + np.dot(z.T,ZtYy) + g1 * np.dot(x.T,L.dot(x)))[0,0]

f = [fval(x,z,y,g1)]

exp = 2.0 + consts.FLOAT_EPSILON

while block_iter < 500:
    
    converged =[False,False,False]
    XtYy = np.dot(XtY,t)
    ZtYy = np.dot(ZtY,t)

    x_old = np.copy(x)
    x_new = np.vstack(linear_proj_l1l2(XtYy + g1 * L.dot(x),l1))
    f.append(fval(x_new, z, y, g1))
    x = x_new
        
    z_old = np.copy(z)
    z_new = np.vstack(linear_proj_l1l2(ZtYy,l2))
    f.append(fval(x, z_new, y, g1))
    z = z_new
    
    t_old = np.copy(t)
    t_new = constraint3.proj(np.dot(XtY.T, x) + np.dot(ZtY.T, z))
    XtYy = np.dot(XtY,t_new)
    ZtYy = np.dot(ZtY,t_new)
    f.append(fval(x_new, z, y, g1))
    t = t_new

    if np.linalg.norm(x_old - x_new) < eps:
        converged[0] = True
    if np.linalg.norm(z_old - z_new) < eps:
        converged[1] = True
    if np.linalg.norm(t_old - t_new) < eps:
        converged[2] = True
    
    if abs(f[-4] - f[-1]) < eps:
        print('New Criterion reached at block iteration: {}'.format(block_iter))
        break

    block_iter += 1
    all_converged = np.array(converged)
    print('blcok iter ',block_iter)
    
    if all_converged.all():
        print('Global Convergence reached at iteration: {}'.format(block_iter))
        break

plt.figure()
plt.plot(x)
print('Graph Smoothness: ', np.dot(x.T,L.dot(x)))

plt.figure()
plt.plot(z)

np.where(x != 0)[0].shape

G=nx.from_scipy_sparse_matrix(adj)
nx.draw(G,node_color=x.ravel(),node_size=10)
genes = np.where(x < 0)[0]
s = pd.Series(x.ravel()[genes],index=data.loc[:,data.columns.str.startswith('GE')].columns[genes])
s = s.sort_values(ascending=True)

with open('genes.txt','a') as l:
    for ge in data.loc[:,data.columns.str.startswith('GE')].columns.str.split('.'):
        l.write(ge[1]+'\n')
