# This file is automatically generated by generate_todo.py.
# Files that start with an underscore ("_") have been excluded.

./parsimony/estimators.py:
-------------------------
87: # TODO: Is this a good name?

282: # TODO: Should we use a seed here so that we get deterministic results?

394: # TODO: Should we use a seed somewhere so that we get deterministic results?

509: # TODO: Should we use a seed here so that we get deterministic results?

629: # TODO: Should we use a seed here so that we get deterministic results?

789: # TODO: Should we use a seed here so that we get deterministic results?

954: # TODO: Should we use a seed here so that we get deterministic results?

1206: # TODO: Should we use a seed here so that we get deterministic results?

1327: # TODO: Should we use a seed here so that we get deterministic results?

1492: # TODO: Should we use a seed here so that we get deterministic results?

1665: # TODO: Should we use a seed here so that we get deterministic results?

1932: # TODO: Should we use a seed here so that we get deterministic
1933: # results?
1934: #                if w is None or k > 0:

2151: # TODO: Should we use a seed here so that we get deterministic
2152: # results?
2153: #                if w is None or k > 0:

./parsimony/utils/plot.py:
-------------------------
68: # TODO: Add the other cases.

./parsimony/utils/utils.py:
--------------------------
24: #TODO: This depends on the OS. We should try to be clever here ...

./parsimony/utils/consts.py:
---------------------------
17: # TODO: MAX_ITER is heavily algorithm-dependent, so we have to think about if
18: # we should include a package-wide maximum at all.

./parsimony/functions/losses.py:
-------------------------------
187: # TODO: Inherit from LinearRegression and add an L2 constraint instead!

364: # TODO: Make the weights sparse.
365: #weights = np.eye(self.X.shape[0])

367: # TODO: Allow the weight vector to be a list.

472: # TODO: Use FastSVD for speedup!

474: self._L = np.max(s) ** 2.0  # TODO: CHECK

635: PWX = 0.5 * np.sqrt(self.weights) * self.X  # TODO: CHECK WITH FOUAD
636: # PW = 0.5 * np.eye(self.X.shape[0]) ## miss np.sqrt(self.W)
637: #PW = 0.5 * np.sqrt(self.W)
638: #PWX = np.dot(PW, self.X)
639: # TODO: Use FastSVD for speedup!

641: self._L = np.max(s) ** 2.0  # TODO: CHECK

646: self._L += self.k  # TODO: CHECK

664: # TODO: Handle mean here?

./parsimony/functions/penalties.py:
----------------------------------
198: # TODO: This should not be able to happen! Do we know it doesn't?

203: # TODO: This should not be able to happen! Do we know it doesn't?

571: # TODO: Check if this is correct!

1340: # TODO: We can share variables between f and df and speed up
1341: # some shared computations.

./parsimony/functions/properties.py:
-----------------------------------
108: # TODO: Should all constraints have the projection operator?

346: # TODO: Should L by default take a weight vector as argument?

./parsimony/functions/combinedfunctions.py:
------------------------------------------
37: # TODO: Add penalty_start and mean to all of these!

109: # TODO: We currently only allow one proximal operator. Fix this!

162: # TODO: We currently only allow one proximal operator. Fix this!

656: # TODO: This is not good. Solve this better!

1159: # TODO: This is not a good solution. Can we solve this in a better way?

1211: # TODO: Use max_iter here!!

1261: # TODO: Kernelise this function! See how I did in
1262: # LinearRegressionL1L2TV._beta_hat.

1304: # TODO: Add this function or refactor API!

1387: # TODO: This is not a nice solution. Can we solve it better?

./parsimony/functions/multiblock/losses.py:
------------------------------------------
899: # TODO: Check instead if it is a numpy array.

./parsimony/functions/nesterov/tv.py:
------------------------------------
150: # TODO: This only work if the elements of self._A are scipy.sparse. We
151: # should allow dense matrices as well.

154: # TODO: Instead of p, this should really be the number of non-zero
155: # rows of A.

165: # TODO: Add max_iter here!

./parsimony/functions/nesterov/l1tv.py:
--------------------------------------
64: # WARNING: Number of non-zero rows may differ from p.

151: # TODO: Instead of p, this should really be the number of non-zero
152: # rows of A.

163: # TODO: Add max_iter here!!

./parsimony/functions/nesterov/grouptv.py:
-----------------------------------------
157: # TODO: This only work if the elements of self._A are scipy.sparse. We
158: # should allow dense matrices as well.

164: # TODO: Add max_iter here!

./parsimony/datasets/regression/dice5.py:
----------------------------------------
35: # TODO: This is wrong. Shape should be Z, Y, X.

./parsimony/algorithms/nipals.py:
--------------------------------
32: # TODO: Add information about the run.

./parsimony/algorithms/primaldual.py:
------------------------------------
203: # TODO: Warn if G_new < 0.

./parsimony/algorithms/utils.py:
-------------------------------
34: # TODO: This class should be replaced with Enum.

265: # TODO: We already have f_mid, so we can return a better approximation
266: # here!

356: # TODO: Handle the other cases!

368: # TODO: We seek a root, i.e. where f(x) = 0. The stopping criterion
369: #       should (could?) thus be abs(f(x)) <= eps!

388: if abs(x - x_) <= self.eps:  # TODO: Stopping criterion. See above!

./parsimony/algorithms/bases.py:
-------------------------------
57: # TODO: Replace the one in BaseAlgorithm.

./parsimony/algorithms/proximal.py:
----------------------------------
324: else:  # TODO: Fix this!

400: # TODO: Investigate what is a good default value here!

454: # TODO: Investigate what is a good default value here!

507: # TODO: Investigate what is a good default value here!

546: # TODO: Does the weights really matter when the function is the
547: # indicator function?

581: # TODO: Investigate what is a good default value here!

