<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>parsimony.functions.losses</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="parsimony-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

      <th class="navbar" width="100%"></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        <a href="parsimony-module.html">Package&nbsp;parsimony</a> ::
        <a href="parsimony.functions-module.html">Package&nbsp;functions</a> ::
        Module&nbsp;losses
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options">[<a href="javascript:void(0);" class="privatelink"
    onclick="toggle_private();">hide&nbsp;private</a>]</span></td></tr>
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="parsimony.functions.losses-pysrc.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<h1 class="epydoc">Source Code for <a href="parsimony.functions.losses-module.html">Module parsimony.functions.losses</a></h1>
<pre class="py-src">
<a name="L1"></a><tt class="py-lineno">  1</tt>  <tt class="py-line"><tt class="py-comment"># -*- coding: utf-8 -*-</tt> </tt>
<a name="L2"></a><tt class="py-lineno">  2</tt>  <tt class="py-line"><tt class="py-docstring">"""</tt> </tt>
<a name="L3"></a><tt class="py-lineno">  3</tt>  <tt class="py-line"><tt class="py-docstring">The :mod:`parsimony.functions.losses` module contains the loss functions used</tt> </tt>
<a name="L4"></a><tt class="py-lineno">  4</tt>  <tt class="py-line"><tt class="py-docstring">throughout the package. These represent mathematical functions and should thus</tt> </tt>
<a name="L5"></a><tt class="py-lineno">  5</tt>  <tt class="py-line"><tt class="py-docstring">have properties used by the corresponding algorithms. These properties are</tt> </tt>
<a name="L6"></a><tt class="py-lineno">  6</tt>  <tt class="py-line"><tt class="py-docstring">defined in :mod:`parsimony.functions.properties`.</tt> </tt>
<a name="L7"></a><tt class="py-lineno">  7</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L8"></a><tt class="py-lineno">  8</tt>  <tt class="py-line"><tt class="py-docstring">Loss functions should be stateless. Loss functions may be shared and copied</tt> </tt>
<a name="L9"></a><tt class="py-lineno">  9</tt>  <tt class="py-line"><tt class="py-docstring">and should therefore not hold anything that cannot be recomputed the next time</tt> </tt>
<a name="L10"></a><tt class="py-lineno"> 10</tt>  <tt class="py-line"><tt class="py-docstring">it is called.</tt> </tt>
<a name="L11"></a><tt class="py-lineno"> 11</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L12"></a><tt class="py-lineno"> 12</tt>  <tt class="py-line"><tt class="py-docstring">Created on Mon Apr 22 10:54:29 2013</tt> </tt>
<a name="L13"></a><tt class="py-lineno"> 13</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L14"></a><tt class="py-lineno"> 14</tt>  <tt class="py-line"><tt class="py-docstring">Copyright (c) 2013-2014, CEA/DSV/I2BM/Neurospin. All rights reserved.</tt> </tt>
<a name="L15"></a><tt class="py-lineno"> 15</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L16"></a><tt class="py-lineno"> 16</tt>  <tt class="py-line"><tt class="py-docstring">@author:  Tommy L&#246;fstedt, Vincent Guillemot, Edouard Duchesnay and</tt> </tt>
<a name="L17"></a><tt class="py-lineno"> 17</tt>  <tt class="py-line"><tt class="py-docstring">          Fouad Hadj-Selem</tt> </tt>
<a name="L18"></a><tt class="py-lineno"> 18</tt>  <tt class="py-line"><tt class="py-docstring">@email:   lofstedt.tommy@gmail.com, edouard.duchesnay@cea.fr</tt> </tt>
<a name="L19"></a><tt class="py-lineno"> 19</tt>  <tt class="py-line"><tt class="py-docstring">@license: BSD 3-clause.</tt> </tt>
<a name="L20"></a><tt class="py-lineno"> 20</tt>  <tt class="py-line"><tt class="py-docstring">"""</tt> </tt>
<a name="L21"></a><tt class="py-lineno"> 21</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">numpy</tt> <tt class="py-keyword">as</tt> <tt class="py-name">np</tt> </tt>
<a name="L22"></a><tt class="py-lineno"> 22</tt>  <tt class="py-line"> </tt>
<a name="L23"></a><tt class="py-lineno"> 23</tt>  <tt class="py-line"><tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L24"></a><tt class="py-lineno"> 24</tt>  <tt class="py-line">    <tt class="py-keyword">from</tt> <tt class="py-op">.</tt> <tt class="py-keyword">import</tt> <tt id="link-0" class="py-name" targets="Module parsimony.functions.multiblock.properties=parsimony.functions.multiblock.properties-module.html,Module parsimony.functions.nesterov.properties=parsimony.functions.nesterov.properties-module.html,Module parsimony.functions.properties=parsimony.functions.properties-module.html"><a title="parsimony.functions.multiblock.properties
parsimony.functions.nesterov.properties
parsimony.functions.properties" class="py-name" href="#" onclick="return doclink('link-0', 'properties', 'link-0');">properties</a></tt>  <tt class="py-comment"># Only works when imported as a package.</tt> </tt>
<a name="L25"></a><tt class="py-lineno"> 25</tt>  <tt class="py-line"><tt class="py-keyword">except</tt> <tt class="py-name">ValueError</tt><tt class="py-op">:</tt> </tt>
<a name="L26"></a><tt class="py-lineno"> 26</tt>  <tt class="py-line">    <tt class="py-keyword">import</tt> <tt id="link-1" class="py-name" targets="Package parsimony=parsimony-module.html"><a title="parsimony" class="py-name" href="#" onclick="return doclink('link-1', 'parsimony', 'link-1');">parsimony</a></tt><tt class="py-op">.</tt><tt id="link-2" class="py-name" targets="Package parsimony.functions=parsimony.functions-module.html"><a title="parsimony.functions" class="py-name" href="#" onclick="return doclink('link-2', 'functions', 'link-2');">functions</a></tt><tt class="py-op">.</tt><tt id="link-3" class="py-name"><a title="parsimony.functions.multiblock.properties
parsimony.functions.nesterov.properties
parsimony.functions.properties" class="py-name" href="#" onclick="return doclink('link-3', 'properties', 'link-0');">properties</a></tt> <tt class="py-keyword">as</tt> <tt id="link-4" class="py-name"><a title="parsimony.functions.multiblock.properties
parsimony.functions.nesterov.properties
parsimony.functions.properties" class="py-name" href="#" onclick="return doclink('link-4', 'properties', 'link-0');">properties</a></tt>  <tt class="py-comment"># Run as a script.</tt> </tt>
<a name="L27"></a><tt class="py-lineno"> 27</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt id="link-5" class="py-name"><a title="parsimony" class="py-name" href="#" onclick="return doclink('link-5', 'parsimony', 'link-1');">parsimony</a></tt><tt class="py-op">.</tt><tt id="link-6" class="py-name" targets="Module parsimony.algorithms.utils=parsimony.algorithms.utils-module.html,Module parsimony.datasets.simulate.utils=parsimony.datasets.simulate.utils-module.html,Module parsimony.datasets.utils=parsimony.datasets.utils-module.html,Package parsimony.utils=parsimony.utils-module.html,Module parsimony.utils.utils=parsimony.utils.utils-module.html"><a title="parsimony.algorithms.utils
parsimony.datasets.simulate.utils
parsimony.datasets.utils
parsimony.utils
parsimony.utils.utils" class="py-name" href="#" onclick="return doclink('link-6', 'utils', 'link-6');">utils</a></tt> <tt class="py-keyword">as</tt> <tt id="link-7" class="py-name"><a title="parsimony.algorithms.utils
parsimony.datasets.simulate.utils
parsimony.datasets.utils
parsimony.utils
parsimony.utils.utils" class="py-name" href="#" onclick="return doclink('link-7', 'utils', 'link-6');">utils</a></tt> </tt>
<a name="L28"></a><tt class="py-lineno"> 28</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt id="link-8" class="py-name"><a title="parsimony" class="py-name" href="#" onclick="return doclink('link-8', 'parsimony', 'link-1');">parsimony</a></tt><tt class="py-op">.</tt><tt id="link-9" class="py-name"><a title="parsimony.algorithms.utils
parsimony.datasets.simulate.utils
parsimony.datasets.utils
parsimony.utils
parsimony.utils.utils" class="py-name" href="#" onclick="return doclink('link-9', 'utils', 'link-6');">utils</a></tt><tt class="py-op">.</tt><tt id="link-10" class="py-name" targets="Module parsimony.utils.consts=parsimony.utils.consts-module.html"><a title="parsimony.utils.consts" class="py-name" href="#" onclick="return doclink('link-10', 'consts', 'link-10');">consts</a></tt> <tt class="py-keyword">as</tt> <tt id="link-11" class="py-name"><a title="parsimony.utils.consts" class="py-name" href="#" onclick="return doclink('link-11', 'consts', 'link-10');">consts</a></tt> </tt>
<a name="L29"></a><tt class="py-lineno"> 29</tt>  <tt class="py-line"> </tt>
<a name="L30"></a><tt class="py-lineno"> 30</tt>  <tt class="py-line"><tt class="py-name">__all__</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-string">"LinearRegression"</tt><tt class="py-op">,</tt> <tt class="py-string">"RidgeRegression"</tt><tt class="py-op">,</tt> </tt>
<a name="L31"></a><tt class="py-lineno"> 31</tt>  <tt class="py-line">           <tt class="py-string">"LogisticRegression"</tt><tt class="py-op">,</tt> <tt class="py-string">"RidgeLogisticRegression"</tt><tt class="py-op">,</tt> </tt>
<a name="L32"></a><tt class="py-lineno"> 32</tt>  <tt class="py-line">           <tt class="py-string">"LatentVariableVariance"</tt><tt class="py-op">,</tt> <tt class="py-string">"LinearFunction"</tt><tt class="py-op">]</tt> </tt>
<a name="LinearRegression"></a><div id="LinearRegression-def"><a name="L33"></a><tt class="py-lineno"> 33</tt>  <tt class="py-line"> </tt>
<a name="L34"></a><tt class="py-lineno"> 34</tt>  <tt class="py-line"> </tt>
<a name="L35"></a><tt class="py-lineno"> 35</tt> <a class="py-toggle" href="#" id="LinearRegression-toggle" onclick="return toggle('LinearRegression');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearRegression-class.html">LinearRegression</a><tt class="py-op">(</tt><tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">CompositeFunction</tt><tt class="py-op">,</tt> </tt>
<a name="L36"></a><tt class="py-lineno"> 36</tt>  <tt class="py-line">                       <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">Gradient</tt><tt class="py-op">,</tt> </tt>
<a name="L37"></a><tt class="py-lineno"> 37</tt>  <tt class="py-line">                       <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">LipschitzContinuousGradient</tt><tt class="py-op">,</tt> </tt>
<a name="L38"></a><tt class="py-lineno"> 38</tt>  <tt class="py-line">                       <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">StepSize</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearRegression-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="LinearRegression-expanded"><a name="L39"></a><tt class="py-lineno"> 39</tt>  <tt class="py-line">    <tt class="py-docstring">"""The Linear regression loss function.</tt> </tt>
<a name="L40"></a><tt class="py-lineno"> 40</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="LinearRegression.__init__"></a><div id="LinearRegression.__init__-def"><a name="L41"></a><tt class="py-lineno"> 41</tt> <a class="py-toggle" href="#" id="LinearRegression.__init__-toggle" onclick="return toggle('LinearRegression.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearRegression-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">X</tt><tt class="py-op">,</tt> <tt class="py-param">y</tt><tt class="py-op">,</tt> <tt class="py-param">mean</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearRegression.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearRegression.__init__-expanded"><a name="L42"></a><tt class="py-lineno"> 42</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L43"></a><tt class="py-lineno"> 43</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L44"></a><tt class="py-lineno"> 44</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L45"></a><tt class="py-lineno"> 45</tt>  <tt class="py-line"><tt class="py-docstring">        X : Numpy array (n-by-p). The regressor matrix.</tt> </tt>
<a name="L46"></a><tt class="py-lineno"> 46</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L47"></a><tt class="py-lineno"> 47</tt>  <tt class="py-line"><tt class="py-docstring">        y : Numpy array (n-by-1). The regressand vector.</tt> </tt>
<a name="L48"></a><tt class="py-lineno"> 48</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L49"></a><tt class="py-lineno"> 49</tt>  <tt class="py-line"><tt class="py-docstring">        k : Non-negative float. The ridge parameter.</tt> </tt>
<a name="L50"></a><tt class="py-lineno"> 50</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L51"></a><tt class="py-lineno"> 51</tt>  <tt class="py-line"><tt class="py-docstring">        mean : Boolean. Whether to compute the squared loss or the mean</tt> </tt>
<a name="L52"></a><tt class="py-lineno"> 52</tt>  <tt class="py-line"><tt class="py-docstring">                squared loss. Default is True, the mean squared loss.</tt> </tt>
<a name="L53"></a><tt class="py-lineno"> 53</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L54"></a><tt class="py-lineno"> 54</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt> <tt class="py-op">=</tt> <tt class="py-name">X</tt> </tt>
<a name="L55"></a><tt class="py-lineno"> 55</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">=</tt> <tt class="py-name">y</tt> </tt>
<a name="L56"></a><tt class="py-lineno"> 56</tt>  <tt class="py-line"> </tt>
<a name="L57"></a><tt class="py-lineno"> 57</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt> <tt class="py-op">=</tt> <tt class="py-name">bool</tt><tt class="py-op">(</tt><tt class="py-name">mean</tt><tt class="py-op">)</tt> </tt>
<a name="L58"></a><tt class="py-lineno"> 58</tt>  <tt class="py-line"> </tt>
<a name="L59"></a><tt class="py-lineno"> 59</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-12" class="py-name" targets="Method parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.reset()=parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV-class.html#reset,Method parsimony.functions.combinedfunctions.CombinedFunction.reset()=parsimony.functions.combinedfunctions.CombinedFunction-class.html#reset,Method parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.reset()=parsimony.functions.combinedfunctions.LinearRegressionL1L2GL-class.html#reset,Method parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.reset()=parsimony.functions.combinedfunctions.LinearRegressionL1L2TV-class.html#reset,Method parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.reset()=parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV-class.html#reset,Method parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.reset()=parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV-class.html#reset,Method parsimony.functions.losses.LatentVariableVariance.reset()=parsimony.functions.losses.LatentVariableVariance-class.html#reset,Method parsimony.functions.losses.LinearFunction.reset()=parsimony.functions.losses.LinearFunction-class.html#reset,Method parsimony.functions.losses.LinearRegression.reset()=parsimony.functions.losses.LinearRegression-class.html#reset,Method parsimony.functions.losses.LogisticRegression.reset()=parsimony.functions.losses.LogisticRegression-class.html#reset,Method parsimony.functions.losses.RidgeLogisticRegression.reset()=parsimony.functions.losses.RidgeLogisticRegression-class.html#reset,Method parsimony.functions.losses.RidgeRegression.reset()=parsimony.functions.losses.RidgeRegression-class.html#reset,Method parsimony.functions.multiblock.losses.CombinedMultiblockFunction.reset()=parsimony.functions.multiblock.losses.CombinedMultiblockFunction-class.html#reset,Method parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset()=parsimony.functions.multiblock.losses.GeneralisedMultiblock-class.html#reset,Method parsimony.functions.multiblock.losses.LatentVariableCovariance.reset()=parsimony.functions.multiblock.losses.LatentVariableCovariance-class.html#reset,Method parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.reset()=parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared-class.html#reset,Method parsimony.functions.nesterov.gl.GroupLassoOverlap.reset()=parsimony.functions.nesterov.gl.GroupLassoOverlap-class.html#reset,Method parsimony.functions.nesterov.grouptv.GroupTotalVariation.reset()=parsimony.functions.nesterov.grouptv.GroupTotalVariation-class.html#reset,Method parsimony.functions.nesterov.l1tv.L1TV.reset()=parsimony.functions.nesterov.l1tv.L1TV-class.html#reset,Method parsimony.functions.nesterov.tv.TotalVariation.reset()=parsimony.functions.nesterov.tv.TotalVariation-class.html#reset,Method parsimony.functions.penalties.LinearVariableConstraint.reset()=parsimony.functions.penalties.LinearVariableConstraint-class.html#reset,Method parsimony.functions.penalties.RGCCAConstraint.reset()=parsimony.functions.penalties.RGCCAConstraint-class.html#reset,Method parsimony.functions.penalties.RidgeSquaredError.reset()=parsimony.functions.penalties.RidgeSquaredError-class.html#reset,Method parsimony.functions.penalties.ZeroFunction.reset()=parsimony.functions.penalties.ZeroFunction-class.html#reset,Method parsimony.functions.properties.Function.reset()=parsimony.functions.properties.Function-class.html#reset"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.CombinedFunction.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.reset
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.reset
parsimony.functions.losses.LatentVariableVariance.reset
parsimony.functions.losses.LinearFunction.reset
parsimony.functions.losses.LinearRegression.reset
parsimony.functions.losses.LogisticRegression.reset
parsimony.functions.losses.RidgeLogisticRegression.reset
parsimony.functions.losses.RidgeRegression.reset
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.reset
parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset
parsimony.functions.multiblock.losses.LatentVariableCovariance.reset
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.reset
parsimony.functions.nesterov.gl.GroupLassoOverlap.reset
parsimony.functions.nesterov.grouptv.GroupTotalVariation.reset
parsimony.functions.nesterov.l1tv.L1TV.reset
parsimony.functions.nesterov.tv.TotalVariation.reset
parsimony.functions.penalties.LinearVariableConstraint.reset
parsimony.functions.penalties.RGCCAConstraint.reset
parsimony.functions.penalties.RidgeSquaredError.reset
parsimony.functions.penalties.ZeroFunction.reset
parsimony.functions.properties.Function.reset" class="py-name" href="#" onclick="return doclink('link-12', 'reset', 'link-12');">reset</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L60"></a><tt class="py-lineno"> 60</tt>  <tt class="py-line"> </tt>
<a name="LinearRegression.reset"></a><div id="LinearRegression.reset-def"><a name="L61"></a><tt class="py-lineno"> 61</tt> <a class="py-toggle" href="#" id="LinearRegression.reset-toggle" onclick="return toggle('LinearRegression.reset');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearRegression-class.html#reset">reset</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearRegression.reset-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearRegression.reset-expanded"><a name="L62"></a><tt class="py-lineno"> 62</tt>  <tt class="py-line">        <tt class="py-docstring">"""Free any cached computations from previous use of this Function.</tt> </tt>
<a name="L63"></a><tt class="py-lineno"> 63</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L64"></a><tt class="py-lineno"> 64</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L65"></a><tt class="py-lineno"> 65</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L66"></a><tt class="py-lineno"> 66</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L67"></a><tt class="py-lineno"> 67</tt>  <tt class="py-line"> </tt>
<a name="LinearRegression.f"></a><div id="LinearRegression.f-def"><a name="L68"></a><tt class="py-lineno"> 68</tt> <a class="py-toggle" href="#" id="LinearRegression.f-toggle" onclick="return toggle('LinearRegression.f');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearRegression-class.html#f">f</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearRegression.f-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearRegression.f-expanded"><a name="L69"></a><tt class="py-lineno"> 69</tt>  <tt class="py-line">        <tt class="py-docstring">"""Function value.</tt> </tt>
<a name="L70"></a><tt class="py-lineno"> 70</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L71"></a><tt class="py-lineno"> 71</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L72"></a><tt class="py-lineno"> 72</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L73"></a><tt class="py-lineno"> 73</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L74"></a><tt class="py-lineno"> 74</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L75"></a><tt class="py-lineno"> 75</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. Regression coefficient vector. The point at which</tt> </tt>
<a name="L76"></a><tt class="py-lineno"> 76</tt>  <tt class="py-line"><tt class="py-docstring">                to evaluate the function.</tt> </tt>
<a name="L77"></a><tt class="py-lineno"> 77</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L78"></a><tt class="py-lineno"> 78</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L79"></a><tt class="py-lineno"> 79</tt>  <tt class="py-line">            <tt class="py-name">d</tt> <tt class="py-op">=</tt> <tt class="py-number">2.0</tt> <tt class="py-op">*</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L80"></a><tt class="py-lineno"> 80</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L81"></a><tt class="py-lineno"> 81</tt>  <tt class="py-line">            <tt class="py-name">d</tt> <tt class="py-op">=</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L82"></a><tt class="py-lineno"> 82</tt>  <tt class="py-line"> </tt>
<a name="L83"></a><tt class="py-lineno"> 83</tt>  <tt class="py-line">        <tt id="link-13" class="py-name" targets="Method parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.f()=parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV-class.html#f,Method parsimony.functions.combinedfunctions.CombinedFunction.f()=parsimony.functions.combinedfunctions.CombinedFunction-class.html#f,Method parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.f()=parsimony.functions.combinedfunctions.LinearRegressionL1L2GL-class.html#f,Method parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.f()=parsimony.functions.combinedfunctions.LinearRegressionL1L2TV-class.html#f,Method parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.f()=parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV-class.html#f,Method parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.f()=parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV-class.html#f,Method parsimony.functions.losses.LatentVariableVariance.f()=parsimony.functions.losses.LatentVariableVariance-class.html#f,Method parsimony.functions.losses.LinearFunction.f()=parsimony.functions.losses.LinearFunction-class.html#f,Method parsimony.functions.losses.LinearRegression.f()=parsimony.functions.losses.LinearRegression-class.html#f,Method parsimony.functions.losses.LogisticRegression.f()=parsimony.functions.losses.LogisticRegression-class.html#f,Method parsimony.functions.losses.RidgeLogisticRegression.f()=parsimony.functions.losses.RidgeLogisticRegression-class.html#f,Method parsimony.functions.losses.RidgeRegression.f()=parsimony.functions.losses.RidgeRegression-class.html#f,Method parsimony.functions.multiblock.losses.CombinedMultiblockFunction.f()=parsimony.functions.multiblock.losses.CombinedMultiblockFunction-class.html#f,Method parsimony.functions.multiblock.losses.GeneralisedMultiblock.f()=parsimony.functions.multiblock.losses.GeneralisedMultiblock-class.html#f,Method parsimony.functions.multiblock.losses.LatentVariableCovariance.f()=parsimony.functions.multiblock.losses.LatentVariableCovariance-class.html#f,Method parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.f()=parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared-class.html#f,Method parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.f()=parsimony.functions.multiblock.losses.MultiblockFunctionWrapper-class.html#f,Method parsimony.functions.nesterov.gl.GroupLassoOverlap.f()=parsimony.functions.nesterov.gl.GroupLassoOverlap-class.html#f,Method parsimony.functions.nesterov.grouptv.GroupTotalVariation.f()=parsimony.functions.nesterov.grouptv.GroupTotalVariation-class.html#f,Method parsimony.functions.nesterov.l1.L1.f()=parsimony.functions.nesterov.l1.L1-class.html#f,Method parsimony.functions.nesterov.l1tv.L1TV.f()=parsimony.functions.nesterov.l1tv.L1TV-class.html#f,Method parsimony.functions.nesterov.tv.TotalVariation.f()=parsimony.functions.nesterov.tv.TotalVariation-class.html#f,Method parsimony.functions.penalties.L0.f()=parsimony.functions.penalties.L0-class.html#f,Method parsimony.functions.penalties.L1.f()=parsimony.functions.penalties.L1-class.html#f,Method parsimony.functions.penalties.L1L2Squared.f()=parsimony.functions.penalties.L1L2Squared-class.html#f,Method parsimony.functions.penalties.L2.f()=parsimony.functions.penalties.L2-class.html#f,Method parsimony.functions.penalties.L2Squared.f()=parsimony.functions.penalties.L2Squared-class.html#f,Method parsimony.functions.penalties.LInf.f()=parsimony.functions.penalties.LInf-class.html#f,Method parsimony.functions.penalties.LinearVariableConstraint.f()=parsimony.functions.penalties.LinearVariableConstraint-class.html#f,Method parsimony.functions.penalties.QuadraticConstraint.f()=parsimony.functions.penalties.QuadraticConstraint-class.html#f,Method parsimony.functions.penalties.RGCCAConstraint.f()=parsimony.functions.penalties.RGCCAConstraint-class.html#f,Method parsimony.functions.penalties.RidgeSquaredError.f()=parsimony.functions.penalties.RidgeSquaredError-class.html#f,Method parsimony.functions.penalties.SufficientDescentCondition.f()=parsimony.functions.penalties.SufficientDescentCondition-class.html#f,Method parsimony.functions.penalties.ZeroFunction.f()=parsimony.functions.penalties.ZeroFunction-class.html#f,Method parsimony.functions.properties.CombinedProjectionOperator.f()=parsimony.functions.properties.CombinedProjectionOperator-class.html#f,Method parsimony.functions.properties.Function.f()=parsimony.functions.properties.Function-class.html#f,Method parsimony.functions.properties.IndicatorFunction.f()=parsimony.functions.properties.IndicatorFunction-class.html#f,Method parsimony.functions.properties.SplittableFunction.f()=parsimony.functions.properties.SplittableFunction-class.html#f"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.CombinedFunction.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.f
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.f
parsimony.functions.losses.LatentVariableVariance.f
parsimony.functions.losses.LinearFunction.f
parsimony.functions.losses.LinearRegression.f
parsimony.functions.losses.LogisticRegression.f
parsimony.functions.losses.RidgeLogisticRegression.f
parsimony.functions.losses.RidgeRegression.f
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.f
parsimony.functions.multiblock.losses.GeneralisedMultiblock.f
parsimony.functions.multiblock.losses.LatentVariableCovariance.f
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.f
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.f
parsimony.functions.nesterov.gl.GroupLassoOverlap.f
parsimony.functions.nesterov.grouptv.GroupTotalVariation.f
parsimony.functions.nesterov.l1.L1.f
parsimony.functions.nesterov.l1tv.L1TV.f
parsimony.functions.nesterov.tv.TotalVariation.f
parsimony.functions.penalties.L0.f
parsimony.functions.penalties.L1.f
parsimony.functions.penalties.L1L2Squared.f
parsimony.functions.penalties.L2.f
parsimony.functions.penalties.L2Squared.f
parsimony.functions.penalties.LInf.f
parsimony.functions.penalties.LinearVariableConstraint.f
parsimony.functions.penalties.QuadraticConstraint.f
parsimony.functions.penalties.RGCCAConstraint.f
parsimony.functions.penalties.RidgeSquaredError.f
parsimony.functions.penalties.SufficientDescentCondition.f
parsimony.functions.penalties.ZeroFunction.f
parsimony.functions.properties.CombinedProjectionOperator.f
parsimony.functions.properties.Function.f
parsimony.functions.properties.IndicatorFunction.f
parsimony.functions.properties.SplittableFunction.f" class="py-name" href="#" onclick="return doclink('link-13', 'f', 'link-13');">f</a></tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">d</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-14" class="py-name" targets="Method parsimony.utils.linalgs.MultipartArray.dot()=parsimony.utils.linalgs.MultipartArray-class.html#dot"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-14', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-15" class="py-name" targets="Variable parsimony.algorithms.utils.Info.beta=parsimony.algorithms.utils.Info-class.html#beta,Module parsimony.datasets.simulate.beta=parsimony.datasets.simulate.beta-module.html,Function parsimony.utils.stats.beta()=parsimony.utils.stats-module.html#beta"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-15', 'beta', 'link-15');">beta</a></tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> </tt>
<a name="L84"></a><tt class="py-lineno"> 84</tt>  <tt class="py-line"> </tt>
<a name="L85"></a><tt class="py-lineno"> 85</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-16" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.CombinedFunction.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.f
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.f
parsimony.functions.losses.LatentVariableVariance.f
parsimony.functions.losses.LinearFunction.f
parsimony.functions.losses.LinearRegression.f
parsimony.functions.losses.LogisticRegression.f
parsimony.functions.losses.RidgeLogisticRegression.f
parsimony.functions.losses.RidgeRegression.f
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.f
parsimony.functions.multiblock.losses.GeneralisedMultiblock.f
parsimony.functions.multiblock.losses.LatentVariableCovariance.f
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.f
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.f
parsimony.functions.nesterov.gl.GroupLassoOverlap.f
parsimony.functions.nesterov.grouptv.GroupTotalVariation.f
parsimony.functions.nesterov.l1.L1.f
parsimony.functions.nesterov.l1tv.L1TV.f
parsimony.functions.nesterov.tv.TotalVariation.f
parsimony.functions.penalties.L0.f
parsimony.functions.penalties.L1.f
parsimony.functions.penalties.L1L2Squared.f
parsimony.functions.penalties.L2.f
parsimony.functions.penalties.L2Squared.f
parsimony.functions.penalties.LInf.f
parsimony.functions.penalties.LinearVariableConstraint.f
parsimony.functions.penalties.QuadraticConstraint.f
parsimony.functions.penalties.RGCCAConstraint.f
parsimony.functions.penalties.RidgeSquaredError.f
parsimony.functions.penalties.SufficientDescentCondition.f
parsimony.functions.penalties.ZeroFunction.f
parsimony.functions.properties.CombinedProjectionOperator.f
parsimony.functions.properties.Function.f
parsimony.functions.properties.IndicatorFunction.f
parsimony.functions.properties.SplittableFunction.f" class="py-name" href="#" onclick="return doclink('link-16', 'f', 'link-13');">f</a></tt> </tt>
</div><a name="L86"></a><tt class="py-lineno"> 86</tt>  <tt class="py-line"> </tt>
<a name="LinearRegression.grad"></a><div id="LinearRegression.grad-def"><a name="L87"></a><tt class="py-lineno"> 87</tt> <a class="py-toggle" href="#" id="LinearRegression.grad-toggle" onclick="return toggle('LinearRegression.grad');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearRegression-class.html#grad">grad</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearRegression.grad-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearRegression.grad-expanded"><a name="L88"></a><tt class="py-lineno"> 88</tt>  <tt class="py-line">        <tt class="py-docstring">"""Gradient of the function at beta.</tt> </tt>
<a name="L89"></a><tt class="py-lineno"> 89</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L90"></a><tt class="py-lineno"> 90</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Gradient".</tt> </tt>
<a name="L91"></a><tt class="py-lineno"> 91</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L92"></a><tt class="py-lineno"> 92</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L93"></a><tt class="py-lineno"> 93</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L94"></a><tt class="py-lineno"> 94</tt>  <tt class="py-line"><tt class="py-docstring">        beta : The point at which to evaluate the gradient.</tt> </tt>
<a name="L95"></a><tt class="py-lineno"> 95</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L96"></a><tt class="py-lineno"> 96</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L97"></a><tt class="py-lineno"> 97</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L98"></a><tt class="py-lineno"> 98</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L99"></a><tt class="py-lineno"> 99</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import LinearRegression</tt> </tt>
<a name="L100"></a><tt class="py-lineno">100</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L101"></a><tt class="py-lineno">101</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L102"></a><tt class="py-lineno">102</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(100, 150)</tt> </tt>
<a name="L103"></a><tt class="py-lineno">103</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y = np.random.rand(100, 1)</tt> </tt>
<a name="L104"></a><tt class="py-lineno">104</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; lr = LinearRegression(X=X, y=y)</tt> </tt>
<a name="L105"></a><tt class="py-lineno">105</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; beta = np.random.rand(150, 1)</tt> </tt>
<a name="L106"></a><tt class="py-lineno">106</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(np.linalg.norm(lr.grad(beta)</tt> </tt>
<a name="L107"></a><tt class="py-lineno">107</tt>  <tt class="py-line"><tt class="py-docstring">        ...       - lr.approx_grad(beta, eps=1e-4)), 9)</tt> </tt>
<a name="L108"></a><tt class="py-lineno">108</tt>  <tt class="py-line"><tt class="py-docstring">        1.3e-08</tt> </tt>
<a name="L109"></a><tt class="py-lineno">109</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L110"></a><tt class="py-lineno">110</tt>  <tt class="py-line">        <tt id="link-17" class="py-name" targets="Module parsimony.datasets.simulate.grad=parsimony.datasets.simulate.grad-module.html,Method parsimony.datasets.simulate.grad.Function.grad()=parsimony.datasets.simulate.grad.Function-class.html#grad,Method parsimony.datasets.simulate.grad.L1.grad()=parsimony.datasets.simulate.grad.L1-class.html#grad,Method parsimony.datasets.simulate.grad.L2.grad()=parsimony.datasets.simulate.grad.L2-class.html#grad,Method parsimony.datasets.simulate.grad.L2Squared.grad()=parsimony.datasets.simulate.grad.L2Squared-class.html#grad,Method parsimony.datasets.simulate.grad.NesterovFunction.grad()=parsimony.datasets.simulate.grad.NesterovFunction-class.html#grad,Method parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad()=parsimony.datasets.simulate.grad.SmoothedGroupLasso-class.html#grad,Method parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad()=parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation-class.html#grad,Method parsimony.datasets.simulate.grad.SmoothedL1.grad()=parsimony.datasets.simulate.grad.SmoothedL1-class.html#grad,Method parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad()=parsimony.datasets.simulate.grad.SmoothedTotalVariation-class.html#grad,Method parsimony.datasets.simulate.grad.TotalVariation.grad()=parsimony.datasets.simulate.grad.TotalVariation-class.html#grad,Method parsimony.functions.combinedfunctions.CombinedFunction.grad()=parsimony.functions.combinedfunctions.CombinedFunction-class.html#grad,Method parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad()=parsimony.functions.combinedfunctions.LinearRegressionL1L2GL-class.html#grad,Method parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad()=parsimony.functions.combinedfunctions.LinearRegressionL1L2TV-class.html#grad,Method parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad()=parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV-class.html#grad,Method parsimony.functions.losses.LatentVariableVariance.grad()=parsimony.functions.losses.LatentVariableVariance-class.html#grad,Method parsimony.functions.losses.LinearFunction.grad()=parsimony.functions.losses.LinearFunction-class.html#grad,Method parsimony.functions.losses.LinearRegression.grad()=parsimony.functions.losses.LinearRegression-class.html#grad,Method parsimony.functions.losses.LogisticRegression.grad()=parsimony.functions.losses.LogisticRegression-class.html#grad,Method parsimony.functions.losses.RidgeLogisticRegression.grad()=parsimony.functions.losses.RidgeLogisticRegression-class.html#grad,Method parsimony.functions.losses.RidgeRegression.grad()=parsimony.functions.losses.RidgeRegression-class.html#grad,Method parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad()=parsimony.functions.multiblock.losses.CombinedMultiblockFunction-class.html#grad,Method parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad()=parsimony.functions.multiblock.losses.GeneralisedMultiblock-class.html#grad,Method parsimony.functions.multiblock.losses.LatentVariableCovariance.grad()=parsimony.functions.multiblock.losses.LatentVariableCovariance-class.html#grad,Method parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad()=parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared-class.html#grad,Method parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad()=parsimony.functions.multiblock.losses.MultiblockFunctionWrapper-class.html#grad,Method parsimony.functions.multiblock.properties.MultiblockGradient.grad()=parsimony.functions.multiblock.properties.MultiblockGradient-class.html#grad,Method parsimony.functions.nesterov.l1.L1.grad()=parsimony.functions.nesterov.l1.L1-class.html#grad,Method parsimony.functions.penalties.L2Squared.grad()=parsimony.functions.penalties.L2Squared-class.html#grad,Method parsimony.functions.penalties.QuadraticConstraint.grad()=parsimony.functions.penalties.QuadraticConstraint-class.html#grad,Method parsimony.functions.penalties.RGCCAConstraint.grad()=parsimony.functions.penalties.RGCCAConstraint-class.html#grad,Method parsimony.functions.penalties.RidgeSquaredError.grad()=parsimony.functions.penalties.RidgeSquaredError-class.html#grad,Method parsimony.functions.penalties.ZeroFunction.grad()=parsimony.functions.penalties.ZeroFunction-class.html#grad,Method parsimony.functions.properties.Gradient.grad()=parsimony.functions.properties.Gradient-class.html#grad,Method parsimony.functions.properties.NesterovFunction.grad()=parsimony.functions.properties.NesterovFunction-class.html#grad"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-17', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-18" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-18', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt id="link-19" class="py-name" targets="Variable parsimony.utils.linalgs.MultipartArray.T=parsimony.utils.linalgs.MultipartArray-class.html#T"><a title="parsimony.utils.linalgs.MultipartArray.T" class="py-name" href="#" onclick="return doclink('link-19', 'T', 'link-19');">T</a></tt><tt class="py-op">,</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-20" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-20', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-21" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-21', 'beta', 'link-15');">beta</a></tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt><tt class="py-op">)</tt> </tt>
<a name="L111"></a><tt class="py-lineno">111</tt>  <tt class="py-line"> </tt>
<a name="L112"></a><tt class="py-lineno">112</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L113"></a><tt class="py-lineno">113</tt>  <tt class="py-line">            <tt id="link-22" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-22', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">*=</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L114"></a><tt class="py-lineno">114</tt>  <tt class="py-line"> </tt>
<a name="L115"></a><tt class="py-lineno">115</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-23" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-23', 'grad', 'link-17');">grad</a></tt> </tt>
</div><a name="L116"></a><tt class="py-lineno">116</tt>  <tt class="py-line"> </tt>
<a name="LinearRegression.L"></a><div id="LinearRegression.L-def"><a name="L117"></a><tt class="py-lineno">117</tt> <a class="py-toggle" href="#" id="LinearRegression.L-toggle" onclick="return toggle('LinearRegression.L');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearRegression-class.html#L">L</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearRegression.L-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearRegression.L-expanded"><a name="L118"></a><tt class="py-lineno">118</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lipschitz constant of the gradient.</tt> </tt>
<a name="L119"></a><tt class="py-lineno">119</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L120"></a><tt class="py-lineno">120</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "LipschitzContinuousGradient".</tt> </tt>
<a name="L121"></a><tt class="py-lineno">121</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L122"></a><tt class="py-lineno">122</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L123"></a><tt class="py-lineno">123</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L124"></a><tt class="py-lineno">124</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L125"></a><tt class="py-lineno">125</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import LinearRegression</tt> </tt>
<a name="L126"></a><tt class="py-lineno">126</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L127"></a><tt class="py-lineno">127</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L128"></a><tt class="py-lineno">128</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(10, 15)</tt> </tt>
<a name="L129"></a><tt class="py-lineno">129</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y = np.random.rand(10, 1)</tt> </tt>
<a name="L130"></a><tt class="py-lineno">130</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; lr = LinearRegression(X=X, y=y)</tt> </tt>
<a name="L131"></a><tt class="py-lineno">131</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L = lr.L()</tt> </tt>
<a name="L132"></a><tt class="py-lineno">132</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L_ = lr.approx_L((15, 1), 10000)</tt> </tt>
<a name="L133"></a><tt class="py-lineno">133</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L &gt;= L_</tt> </tt>
<a name="L134"></a><tt class="py-lineno">134</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L135"></a><tt class="py-lineno">135</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round((L - L_) / L, 14)</tt> </tt>
<a name="L136"></a><tt class="py-lineno">136</tt>  <tt class="py-line"><tt class="py-docstring">        0.14039091870818</tt> </tt>
<a name="L137"></a><tt class="py-lineno">137</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L138"></a><tt class="py-lineno">138</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L139"></a><tt class="py-lineno">139</tt>  <tt class="py-line"> </tt>
<a name="L140"></a><tt class="py-lineno">140</tt>  <tt class="py-line">            <tt class="py-keyword">from</tt> <tt id="link-24" class="py-name"><a title="parsimony" class="py-name" href="#" onclick="return doclink('link-24', 'parsimony', 'link-1');">parsimony</a></tt><tt class="py-op">.</tt><tt id="link-25" class="py-name" targets="Package parsimony.algorithms=parsimony.algorithms-module.html"><a title="parsimony.algorithms" class="py-name" href="#" onclick="return doclink('link-25', 'algorithms', 'link-25');">algorithms</a></tt><tt class="py-op">.</tt><tt id="link-26" class="py-name" targets="Module parsimony.algorithms.nipals=parsimony.algorithms.nipals-module.html"><a title="parsimony.algorithms.nipals" class="py-name" href="#" onclick="return doclink('link-26', 'nipals', 'link-26');">nipals</a></tt> <tt class="py-keyword">import</tt> <tt id="link-27" class="py-name" targets="Class parsimony.algorithms.nipals.FastSVD=parsimony.algorithms.nipals.FastSVD-class.html"><a title="parsimony.algorithms.nipals.FastSVD" class="py-name" href="#" onclick="return doclink('link-27', 'FastSVD', 'link-27');">FastSVD</a></tt> </tt>
<a name="L141"></a><tt class="py-lineno">141</tt>  <tt class="py-line"> </tt>
<a name="L142"></a><tt class="py-lineno">142</tt>  <tt class="py-line">            <tt class="py-comment"># Rough limits for when FastSVD is faster than np.linalg.svd.</tt> </tt>
<a name="L143"></a><tt class="py-lineno">143</tt>  <tt class="py-line">            <tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt> </tt>
<a name="L144"></a><tt class="py-lineno">144</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-op">(</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">500</tt> <tt class="py-keyword">and</tt> <tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;=</tt> <tt class="py-number">1000</tt> \ </tt>
<a name="L145"></a><tt class="py-lineno">145</tt>  <tt class="py-line">                    <tt class="py-keyword">and</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-op">/</tt> <tt class="py-name">min</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;=</tt> <tt class="py-number">1.3</tt><tt class="py-op">)</tt> \ </tt>
<a name="L146"></a><tt class="py-lineno">146</tt>  <tt class="py-line">               <tt class="py-keyword">or</tt> <tt class="py-op">(</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">1000</tt> <tt class="py-keyword">and</tt> <tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;=</tt> <tt class="py-number">5000</tt> \ </tt>
<a name="L147"></a><tt class="py-lineno">147</tt>  <tt class="py-line">                    <tt class="py-keyword">and</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-op">/</tt> <tt class="py-name">min</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;=</tt> <tt class="py-number">5.0</tt><tt class="py-op">)</tt> \ </tt>
<a name="L148"></a><tt class="py-lineno">148</tt>  <tt class="py-line">               <tt class="py-keyword">or</tt> <tt class="py-op">(</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">5000</tt> <tt class="py-keyword">and</tt> <tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;=</tt> <tt class="py-number">10000</tt> \ </tt>
<a name="L149"></a><tt class="py-lineno">149</tt>  <tt class="py-line">                       <tt class="py-keyword">and</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-op">/</tt> <tt class="py-name">min</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;=</tt> <tt class="py-number">15.0</tt><tt class="py-op">)</tt> \ </tt>
<a name="L150"></a><tt class="py-lineno">150</tt>  <tt class="py-line">               <tt class="py-keyword">or</tt> <tt class="py-op">(</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">10000</tt> <tt class="py-keyword">and</tt> <tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;=</tt> <tt class="py-number">20000</tt> \ </tt>
<a name="L151"></a><tt class="py-lineno">151</tt>  <tt class="py-line">                       <tt class="py-keyword">and</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-op">/</tt> <tt class="py-name">min</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;=</tt> <tt class="py-number">200.0</tt><tt class="py-op">)</tt> \ </tt>
<a name="L152"></a><tt class="py-lineno">152</tt>  <tt class="py-line">               <tt class="py-keyword">or</tt> <tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">10000</tt><tt class="py-op">:</tt> </tt>
<a name="L153"></a><tt class="py-lineno">153</tt>  <tt class="py-line"> </tt>
<a name="L154"></a><tt class="py-lineno">154</tt>  <tt class="py-line">                <tt class="py-name">v</tt> <tt class="py-op">=</tt> <tt id="link-28" class="py-name"><a title="parsimony.algorithms.nipals.FastSVD" class="py-name" href="#" onclick="return doclink('link-28', 'FastSVD', 'link-27');">FastSVD</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-29" class="py-name" targets="Method parsimony.algorithms.bases.ExplicitAlgorithm.run()=parsimony.algorithms.bases.ExplicitAlgorithm-class.html#run,Method parsimony.algorithms.bases.ImplicitAlgorithm.run()=parsimony.algorithms.bases.ImplicitAlgorithm-class.html#run,Method parsimony.algorithms.cluster.KMeans.run()=parsimony.algorithms.cluster.KMeans-class.html#run,Method parsimony.algorithms.coordinate.LassoCoordinateDescent.run()=parsimony.algorithms.coordinate.LassoCoordinateDescent-class.html#run,Method parsimony.algorithms.coordinate.ShootingAlgorithm.run()=parsimony.algorithms.coordinate.ShootingAlgorithm-class.html#run,Method parsimony.algorithms.gradient.GradientDescent.run()=parsimony.algorithms.gradient.GradientDescent-class.html#run,Method parsimony.algorithms.multiblock.MultiblockCONESTA.run()=parsimony.algorithms.multiblock.MultiblockCONESTA-class.html#run,Method parsimony.algorithms.multiblock.MultiblockFISTA.run()=parsimony.algorithms.multiblock.MultiblockFISTA-class.html#run,Method parsimony.algorithms.nipals.FastSVD.run()=parsimony.algorithms.nipals.FastSVD-class.html#run,Method parsimony.algorithms.nipals.FastSVDProduct.run()=parsimony.algorithms.nipals.FastSVDProduct-class.html#run,Method parsimony.algorithms.nipals.FastSparseSVD.run()=parsimony.algorithms.nipals.FastSparseSVD-class.html#run,Method parsimony.algorithms.nipals.PLSR.run()=parsimony.algorithms.nipals.PLSR-class.html#run,Method parsimony.algorithms.nipals.SparsePLSR.run()=parsimony.algorithms.nipals.SparsePLSR-class.html#run,Method parsimony.algorithms.primaldual.ExcessiveGapMethod.run()=parsimony.algorithms.primaldual.ExcessiveGapMethod-class.html#run,Method parsimony.algorithms.proximal.ADMM.run()=parsimony.algorithms.proximal.ADMM-class.html#run,Method parsimony.algorithms.proximal.CONESTA.run()=parsimony.algorithms.proximal.CONESTA-class.html#run,Method parsimony.algorithms.proximal.DykstrasProjectionAlgorithm.run()=parsimony.algorithms.proximal.DykstrasProjectionAlgorithm-class.html#run,Method parsimony.algorithms.proximal.DykstrasProximalAlgorithm.run()=parsimony.algorithms.proximal.DykstrasProximalAlgorithm-class.html#run,Method parsimony.algorithms.proximal.FISTA.run()=parsimony.algorithms.proximal.FISTA-class.html#run,Method parsimony.algorithms.proximal.ISTA.run()=parsimony.algorithms.proximal.ISTA-class.html#run,Method parsimony.algorithms.proximal.ParallelDykstrasProjectionAlgorithm.run()=parsimony.algorithms.proximal.ParallelDykstrasProjectionAlgorithm-class.html#run,Method parsimony.algorithms.proximal.ParallelDykstrasProximalAlgorithm.run()=parsimony.algorithms.proximal.ParallelDykstrasProximalAlgorithm-class.html#run,Method parsimony.algorithms.proximal.StaticCONESTA.run()=parsimony.algorithms.proximal.StaticCONESTA-class.html#run,Method parsimony.algorithms.utils.BacktrackingLineSearch.run()=parsimony.algorithms.utils.BacktrackingLineSearch-class.html#run,Method parsimony.algorithms.utils.Bisection.run()=parsimony.algorithms.utils.Bisection-class.html#run,Method parsimony.algorithms.utils.NewtonRaphson.run()=parsimony.algorithms.utils.NewtonRaphson-class.html#run"><a title="parsimony.algorithms.bases.ExplicitAlgorithm.run
parsimony.algorithms.bases.ImplicitAlgorithm.run
parsimony.algorithms.cluster.KMeans.run
parsimony.algorithms.coordinate.LassoCoordinateDescent.run
parsimony.algorithms.coordinate.ShootingAlgorithm.run
parsimony.algorithms.gradient.GradientDescent.run
parsimony.algorithms.multiblock.MultiblockCONESTA.run
parsimony.algorithms.multiblock.MultiblockFISTA.run
parsimony.algorithms.nipals.FastSVD.run
parsimony.algorithms.nipals.FastSVDProduct.run
parsimony.algorithms.nipals.FastSparseSVD.run
parsimony.algorithms.nipals.PLSR.run
parsimony.algorithms.nipals.SparsePLSR.run
parsimony.algorithms.primaldual.ExcessiveGapMethod.run
parsimony.algorithms.proximal.ADMM.run
parsimony.algorithms.proximal.CONESTA.run
parsimony.algorithms.proximal.DykstrasProjectionAlgorithm.run
parsimony.algorithms.proximal.DykstrasProximalAlgorithm.run
parsimony.algorithms.proximal.FISTA.run
parsimony.algorithms.proximal.ISTA.run
parsimony.algorithms.proximal.ParallelDykstrasProjectionAlgorithm.run
parsimony.algorithms.proximal.ParallelDykstrasProximalAlgorithm.run
parsimony.algorithms.proximal.StaticCONESTA.run
parsimony.algorithms.utils.BacktrackingLineSearch.run
parsimony.algorithms.utils.Bisection.run
parsimony.algorithms.utils.NewtonRaphson.run" class="py-name" href="#" onclick="return doclink('link-29', 'run', 'link-29');">run</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">max_iter</tt><tt class="py-op">=</tt><tt class="py-number">1000</tt><tt class="py-op">)</tt> </tt>
<a name="L155"></a><tt class="py-lineno">155</tt>  <tt class="py-line">                <tt class="py-name">us</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-30" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-30', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt><tt class="py-op">)</tt> </tt>
<a name="L156"></a><tt class="py-lineno">156</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-name">us</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> </tt>
<a name="L157"></a><tt class="py-lineno">157</tt>  <tt class="py-line"> </tt>
<a name="L158"></a><tt class="py-lineno">158</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L159"></a><tt class="py-lineno">159</tt>  <tt class="py-line">                <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt><tt class="py-op">.</tt><tt class="py-name">svd</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> </tt>
<a name="L160"></a><tt class="py-lineno">160</tt>  <tt class="py-line">                                  <tt class="py-name">full_matrices</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-name">compute_uv</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt> </tt>
<a name="L161"></a><tt class="py-lineno">161</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L162"></a><tt class="py-lineno">162</tt>  <tt class="py-line"> </tt>
<a name="L163"></a><tt class="py-lineno">163</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L164"></a><tt class="py-lineno">164</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">/=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">)</tt> </tt>
<a name="L165"></a><tt class="py-lineno">165</tt>  <tt class="py-line"> </tt>
<a name="L166"></a><tt class="py-lineno">166</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> </tt>
</div><a name="L167"></a><tt class="py-lineno">167</tt>  <tt class="py-line"> </tt>
<a name="LinearRegression.step"></a><div id="LinearRegression.step-def"><a name="L168"></a><tt class="py-lineno">168</tt> <a class="py-toggle" href="#" id="LinearRegression.step-toggle" onclick="return toggle('LinearRegression.step');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearRegression-class.html#step">step</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">,</tt> <tt class="py-param">index</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearRegression.step-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearRegression.step-expanded"><a name="L169"></a><tt class="py-lineno">169</tt>  <tt class="py-line">        <tt class="py-docstring">"""The step size to use in descent methods.</tt> </tt>
<a name="L170"></a><tt class="py-lineno">170</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L171"></a><tt class="py-lineno">171</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L172"></a><tt class="py-lineno">172</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L173"></a><tt class="py-lineno">173</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. The point at which to determine the step size.</tt> </tt>
<a name="L174"></a><tt class="py-lineno">174</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L175"></a><tt class="py-lineno">175</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-31" class="py-name" targets="Method parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.L()=parsimony.functions.combinedfunctions.LinearRegressionL1L2GL-class.html#L,Method parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.L()=parsimony.functions.combinedfunctions.LinearRegressionL1L2TV-class.html#L,Method parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.L()=parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV-class.html#L,Method parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.L()=parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV-class.html#L,Method parsimony.functions.losses.LatentVariableVariance.L()=parsimony.functions.losses.LatentVariableVariance-class.html#L,Method parsimony.functions.losses.LinearFunction.L()=parsimony.functions.losses.LinearFunction-class.html#L,Method parsimony.functions.losses.LinearRegression.L()=parsimony.functions.losses.LinearRegression-class.html#L,Method parsimony.functions.losses.LogisticRegression.L()=parsimony.functions.losses.LogisticRegression-class.html#L,Method parsimony.functions.losses.RidgeLogisticRegression.L()=parsimony.functions.losses.RidgeLogisticRegression-class.html#L,Method parsimony.functions.losses.RidgeRegression.L()=parsimony.functions.losses.RidgeRegression-class.html#L,Method parsimony.functions.multiblock.losses.LatentVariableCovariance.L()=parsimony.functions.multiblock.losses.LatentVariableCovariance-class.html#L,Method parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.L()=parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared-class.html#L,Method parsimony.functions.multiblock.properties.MultiblockLipschitzContinuousGradient.L()=parsimony.functions.multiblock.properties.MultiblockLipschitzContinuousGradient-class.html#L,Method parsimony.functions.nesterov.gl.GroupLassoOverlap.L()=parsimony.functions.nesterov.gl.GroupLassoOverlap-class.html#L,Method parsimony.functions.nesterov.grouptv.GroupTotalVariation.L()=parsimony.functions.nesterov.grouptv.GroupTotalVariation-class.html#L,Method parsimony.functions.nesterov.l1.L1.L()=parsimony.functions.nesterov.l1.L1-class.html#L,Method parsimony.functions.nesterov.tv.TotalVariation.L()=parsimony.functions.nesterov.tv.TotalVariation-class.html#L,Method parsimony.functions.penalties.L2Squared.L()=parsimony.functions.penalties.L2Squared-class.html#L,Method parsimony.functions.penalties.RidgeSquaredError.L()=parsimony.functions.penalties.RidgeSquaredError-class.html#L,Method parsimony.functions.properties.LipschitzContinuousGradient.L()=parsimony.functions.properties.LipschitzContinuousGradient-class.html#L,Method parsimony.functions.properties.NesterovFunction.L()=parsimony.functions.properties.NesterovFunction-class.html#L"><a title="parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.L
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.L
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.L
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.L
parsimony.functions.losses.LatentVariableVariance.L
parsimony.functions.losses.LinearFunction.L
parsimony.functions.losses.LinearRegression.L
parsimony.functions.losses.LogisticRegression.L
parsimony.functions.losses.RidgeLogisticRegression.L
parsimony.functions.losses.RidgeRegression.L
parsimony.functions.multiblock.losses.LatentVariableCovariance.L
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.L
parsimony.functions.multiblock.properties.MultiblockLipschitzContinuousGradient.L
parsimony.functions.nesterov.gl.GroupLassoOverlap.L
parsimony.functions.nesterov.grouptv.GroupTotalVariation.L
parsimony.functions.nesterov.l1.L1.L
parsimony.functions.nesterov.tv.TotalVariation.L
parsimony.functions.penalties.L2Squared.L
parsimony.functions.penalties.RidgeSquaredError.L
parsimony.functions.properties.LipschitzContinuousGradient.L
parsimony.functions.properties.NesterovFunction.L" class="py-name" href="#" onclick="return doclink('link-31', 'L', 'link-31');">L</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L176"></a><tt class="py-lineno">176</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression"></a><div id="RidgeRegression-def"><a name="L177"></a><tt class="py-lineno">177</tt>  <tt class="py-line"> </tt>
<a name="L178"></a><tt class="py-lineno">178</tt> <a class="py-toggle" href="#" id="RidgeRegression-toggle" onclick="return toggle('RidgeRegression');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html">RidgeRegression</a><tt class="py-op">(</tt><tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">CompositeFunction</tt><tt class="py-op">,</tt> </tt>
<a name="L179"></a><tt class="py-lineno">179</tt>  <tt class="py-line">                      <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">Gradient</tt><tt class="py-op">,</tt> </tt>
<a name="L180"></a><tt class="py-lineno">180</tt>  <tt class="py-line">                      <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">LipschitzContinuousGradient</tt><tt class="py-op">,</tt> </tt>
<a name="L181"></a><tt class="py-lineno">181</tt>  <tt class="py-line">                      <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">StronglyConvex</tt><tt class="py-op">,</tt> </tt>
<a name="L182"></a><tt class="py-lineno">182</tt>  <tt class="py-line">                      <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">StepSize</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="RidgeRegression-expanded"><a name="L183"></a><tt class="py-lineno">183</tt>  <tt class="py-line">    <tt class="py-docstring">"""The Ridge Regression function, i.e. a representation of</tt> </tt>
<a name="L184"></a><tt class="py-lineno">184</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L185"></a><tt class="py-lineno">185</tt>  <tt class="py-line"><tt class="py-docstring">        f(x) = (0.5 / n) * ||Xb - y||&#178;_2 + lambda * 0.5 * ||b||&#178;_2,</tt> </tt>
<a name="L186"></a><tt class="py-lineno">186</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L187"></a><tt class="py-lineno">187</tt>  <tt class="py-line"><tt class="py-docstring">    where ||.||&#178;_2 is the L2 norm.</tt> </tt>
<a name="L188"></a><tt class="py-lineno">188</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L189"></a><tt class="py-lineno">189</tt>  <tt class="py-line">    <tt class="py-comment"># TODO: Inherit from LinearRegression and add an L2 constraint instead!</tt> </tt>
<a name="RidgeRegression.__init__"></a><div id="RidgeRegression.__init__-def"><a name="L190"></a><tt class="py-lineno">190</tt> <a class="py-toggle" href="#" id="RidgeRegression.__init__-toggle" onclick="return toggle('RidgeRegression.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">X</tt><tt class="py-op">,</tt> <tt class="py-param">y</tt><tt class="py-op">,</tt> <tt class="py-param">k</tt><tt class="py-op">,</tt> <tt class="py-param">penalty_start</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-param">mean</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.__init__-expanded"><a name="L191"></a><tt class="py-lineno">191</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L192"></a><tt class="py-lineno">192</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L193"></a><tt class="py-lineno">193</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L194"></a><tt class="py-lineno">194</tt>  <tt class="py-line"><tt class="py-docstring">        X : Numpy array (n-by-p). The regressor matrix.</tt> </tt>
<a name="L195"></a><tt class="py-lineno">195</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L196"></a><tt class="py-lineno">196</tt>  <tt class="py-line"><tt class="py-docstring">        y : Numpy array (n-by-1). The regressand vector.</tt> </tt>
<a name="L197"></a><tt class="py-lineno">197</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L198"></a><tt class="py-lineno">198</tt>  <tt class="py-line"><tt class="py-docstring">        k : Non-negative float. The ridge parameter.</tt> </tt>
<a name="L199"></a><tt class="py-lineno">199</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L200"></a><tt class="py-lineno">200</tt>  <tt class="py-line"><tt class="py-docstring">        penalty_start : Non-negative integer. The number of columns, variables</tt> </tt>
<a name="L201"></a><tt class="py-lineno">201</tt>  <tt class="py-line"><tt class="py-docstring">                etc., to except from penalisation. Equivalently, the first</tt> </tt>
<a name="L202"></a><tt class="py-lineno">202</tt>  <tt class="py-line"><tt class="py-docstring">                index to be penalised. Default is 0, all columns are included.</tt> </tt>
<a name="L203"></a><tt class="py-lineno">203</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L204"></a><tt class="py-lineno">204</tt>  <tt class="py-line"><tt class="py-docstring">        mean : Boolean. Whether to compute the squared loss or the mean</tt> </tt>
<a name="L205"></a><tt class="py-lineno">205</tt>  <tt class="py-line"><tt class="py-docstring">                squared loss. Default is True, the mean squared loss.</tt> </tt>
<a name="L206"></a><tt class="py-lineno">206</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L207"></a><tt class="py-lineno">207</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt> <tt class="py-op">=</tt> <tt class="py-name">X</tt> </tt>
<a name="L208"></a><tt class="py-lineno">208</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">=</tt> <tt class="py-name">y</tt> </tt>
<a name="L209"></a><tt class="py-lineno">209</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">)</tt> </tt>
<a name="L210"></a><tt class="py-lineno">210</tt>  <tt class="py-line"> </tt>
<a name="L211"></a><tt class="py-lineno">211</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt> <tt class="py-op">=</tt> <tt class="py-name">int</tt><tt class="py-op">(</tt><tt class="py-name">penalty_start</tt><tt class="py-op">)</tt> </tt>
<a name="L212"></a><tt class="py-lineno">212</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt> <tt class="py-op">=</tt> <tt class="py-name">bool</tt><tt class="py-op">(</tt><tt class="py-name">mean</tt><tt class="py-op">)</tt> </tt>
<a name="L213"></a><tt class="py-lineno">213</tt>  <tt class="py-line"> </tt>
<a name="L214"></a><tt class="py-lineno">214</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-32" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.CombinedFunction.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.reset
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.reset
parsimony.functions.losses.LatentVariableVariance.reset
parsimony.functions.losses.LinearFunction.reset
parsimony.functions.losses.LinearRegression.reset
parsimony.functions.losses.LogisticRegression.reset
parsimony.functions.losses.RidgeLogisticRegression.reset
parsimony.functions.losses.RidgeRegression.reset
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.reset
parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset
parsimony.functions.multiblock.losses.LatentVariableCovariance.reset
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.reset
parsimony.functions.nesterov.gl.GroupLassoOverlap.reset
parsimony.functions.nesterov.grouptv.GroupTotalVariation.reset
parsimony.functions.nesterov.l1tv.L1TV.reset
parsimony.functions.nesterov.tv.TotalVariation.reset
parsimony.functions.penalties.LinearVariableConstraint.reset
parsimony.functions.penalties.RGCCAConstraint.reset
parsimony.functions.penalties.RidgeSquaredError.reset
parsimony.functions.penalties.ZeroFunction.reset
parsimony.functions.properties.Function.reset" class="py-name" href="#" onclick="return doclink('link-32', 'reset', 'link-12');">reset</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L215"></a><tt class="py-lineno">215</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.reset"></a><div id="RidgeRegression.reset-def"><a name="L216"></a><tt class="py-lineno">216</tt> <a class="py-toggle" href="#" id="RidgeRegression.reset-toggle" onclick="return toggle('RidgeRegression.reset');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#reset">reset</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.reset-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.reset-expanded"><a name="L217"></a><tt class="py-lineno">217</tt>  <tt class="py-line">        <tt class="py-docstring">"""Free any cached computations from previous use of this Function.</tt> </tt>
<a name="L218"></a><tt class="py-lineno">218</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L219"></a><tt class="py-lineno">219</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L220"></a><tt class="py-lineno">220</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L221"></a><tt class="py-lineno">221</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
<a name="L222"></a><tt class="py-lineno">222</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L223"></a><tt class="py-lineno">223</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.f"></a><div id="RidgeRegression.f-def"><a name="L224"></a><tt class="py-lineno">224</tt> <a class="py-toggle" href="#" id="RidgeRegression.f-toggle" onclick="return toggle('RidgeRegression.f');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#f">f</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.f-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.f-expanded"><a name="L225"></a><tt class="py-lineno">225</tt>  <tt class="py-line">        <tt class="py-docstring">"""Function value.</tt> </tt>
<a name="L226"></a><tt class="py-lineno">226</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L227"></a><tt class="py-lineno">227</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L228"></a><tt class="py-lineno">228</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L229"></a><tt class="py-lineno">229</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L230"></a><tt class="py-lineno">230</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L231"></a><tt class="py-lineno">231</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. Regression coefficient vector. The point at which</tt> </tt>
<a name="L232"></a><tt class="py-lineno">232</tt>  <tt class="py-line"><tt class="py-docstring">                to evaluate the function.</tt> </tt>
<a name="L233"></a><tt class="py-lineno">233</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L234"></a><tt class="py-lineno">234</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">0</tt><tt class="py-op">:</tt> </tt>
<a name="L235"></a><tt class="py-lineno">235</tt>  <tt class="py-line">            <tt class="py-name">beta_</tt> <tt class="py-op">=</tt> <tt id="link-33" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-33', 'beta', 'link-15');">beta</a></tt><tt class="py-op">[</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt><tt class="py-op">:</tt><tt class="py-op">,</tt> <tt class="py-op">:</tt><tt class="py-op">]</tt> </tt>
<a name="L236"></a><tt class="py-lineno">236</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L237"></a><tt class="py-lineno">237</tt>  <tt class="py-line">            <tt class="py-name">beta_</tt> <tt class="py-op">=</tt> <tt id="link-34" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-34', 'beta', 'link-15');">beta</a></tt> </tt>
<a name="L238"></a><tt class="py-lineno">238</tt>  <tt class="py-line"> </tt>
<a name="L239"></a><tt class="py-lineno">239</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L240"></a><tt class="py-lineno">240</tt>  <tt class="py-line">            <tt class="py-name">d</tt> <tt class="py-op">=</tt> <tt class="py-number">2.0</tt> <tt class="py-op">*</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L241"></a><tt class="py-lineno">241</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L242"></a><tt class="py-lineno">242</tt>  <tt class="py-line">            <tt class="py-name">d</tt> <tt class="py-op">=</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L243"></a><tt class="py-lineno">243</tt>  <tt class="py-line"> </tt>
<a name="L244"></a><tt class="py-lineno">244</tt>  <tt class="py-line">        <tt id="link-35" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.CombinedFunction.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.f
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.f
parsimony.functions.losses.LatentVariableVariance.f
parsimony.functions.losses.LinearFunction.f
parsimony.functions.losses.LinearRegression.f
parsimony.functions.losses.LogisticRegression.f
parsimony.functions.losses.RidgeLogisticRegression.f
parsimony.functions.losses.RidgeRegression.f
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.f
parsimony.functions.multiblock.losses.GeneralisedMultiblock.f
parsimony.functions.multiblock.losses.LatentVariableCovariance.f
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.f
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.f
parsimony.functions.nesterov.gl.GroupLassoOverlap.f
parsimony.functions.nesterov.grouptv.GroupTotalVariation.f
parsimony.functions.nesterov.l1.L1.f
parsimony.functions.nesterov.l1tv.L1TV.f
parsimony.functions.nesterov.tv.TotalVariation.f
parsimony.functions.penalties.L0.f
parsimony.functions.penalties.L1.f
parsimony.functions.penalties.L1L2Squared.f
parsimony.functions.penalties.L2.f
parsimony.functions.penalties.L2Squared.f
parsimony.functions.penalties.LInf.f
parsimony.functions.penalties.LinearVariableConstraint.f
parsimony.functions.penalties.QuadraticConstraint.f
parsimony.functions.penalties.RGCCAConstraint.f
parsimony.functions.penalties.RidgeSquaredError.f
parsimony.functions.penalties.SufficientDescentCondition.f
parsimony.functions.penalties.ZeroFunction.f
parsimony.functions.properties.CombinedProjectionOperator.f
parsimony.functions.properties.Function.f
parsimony.functions.properties.IndicatorFunction.f
parsimony.functions.properties.SplittableFunction.f" class="py-name" href="#" onclick="return doclink('link-35', 'f', 'link-13');">f</a></tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">d</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-36" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-36', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-37" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-37', 'beta', 'link-15');">beta</a></tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> \ </tt>
<a name="L245"></a><tt class="py-lineno">245</tt>  <tt class="py-line">                <tt class="py-op">+</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">/</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-name">beta_</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> </tt>
<a name="L246"></a><tt class="py-lineno">246</tt>  <tt class="py-line"> </tt>
<a name="L247"></a><tt class="py-lineno">247</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-38" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.CombinedFunction.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.f
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.f
parsimony.functions.losses.LatentVariableVariance.f
parsimony.functions.losses.LinearFunction.f
parsimony.functions.losses.LinearRegression.f
parsimony.functions.losses.LogisticRegression.f
parsimony.functions.losses.RidgeLogisticRegression.f
parsimony.functions.losses.RidgeRegression.f
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.f
parsimony.functions.multiblock.losses.GeneralisedMultiblock.f
parsimony.functions.multiblock.losses.LatentVariableCovariance.f
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.f
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.f
parsimony.functions.nesterov.gl.GroupLassoOverlap.f
parsimony.functions.nesterov.grouptv.GroupTotalVariation.f
parsimony.functions.nesterov.l1.L1.f
parsimony.functions.nesterov.l1tv.L1TV.f
parsimony.functions.nesterov.tv.TotalVariation.f
parsimony.functions.penalties.L0.f
parsimony.functions.penalties.L1.f
parsimony.functions.penalties.L1L2Squared.f
parsimony.functions.penalties.L2.f
parsimony.functions.penalties.L2Squared.f
parsimony.functions.penalties.LInf.f
parsimony.functions.penalties.LinearVariableConstraint.f
parsimony.functions.penalties.QuadraticConstraint.f
parsimony.functions.penalties.RGCCAConstraint.f
parsimony.functions.penalties.RidgeSquaredError.f
parsimony.functions.penalties.SufficientDescentCondition.f
parsimony.functions.penalties.ZeroFunction.f
parsimony.functions.properties.CombinedProjectionOperator.f
parsimony.functions.properties.Function.f
parsimony.functions.properties.IndicatorFunction.f
parsimony.functions.properties.SplittableFunction.f" class="py-name" href="#" onclick="return doclink('link-38', 'f', 'link-13');">f</a></tt> </tt>
</div><a name="L248"></a><tt class="py-lineno">248</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.grad"></a><div id="RidgeRegression.grad-def"><a name="L249"></a><tt class="py-lineno">249</tt> <a class="py-toggle" href="#" id="RidgeRegression.grad-toggle" onclick="return toggle('RidgeRegression.grad');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#grad">grad</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.grad-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.grad-expanded"><a name="L250"></a><tt class="py-lineno">250</tt>  <tt class="py-line">        <tt class="py-docstring">"""Gradient of the function at beta.</tt> </tt>
<a name="L251"></a><tt class="py-lineno">251</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L252"></a><tt class="py-lineno">252</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Gradient".</tt> </tt>
<a name="L253"></a><tt class="py-lineno">253</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L254"></a><tt class="py-lineno">254</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L255"></a><tt class="py-lineno">255</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L256"></a><tt class="py-lineno">256</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. The point at which to evaluate the gradient.</tt> </tt>
<a name="L257"></a><tt class="py-lineno">257</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L258"></a><tt class="py-lineno">258</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L259"></a><tt class="py-lineno">259</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L260"></a><tt class="py-lineno">260</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L261"></a><tt class="py-lineno">261</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import RidgeRegression</tt> </tt>
<a name="L262"></a><tt class="py-lineno">262</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L263"></a><tt class="py-lineno">263</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L264"></a><tt class="py-lineno">264</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(100, 150)</tt> </tt>
<a name="L265"></a><tt class="py-lineno">265</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y = np.random.rand(100, 1)</tt> </tt>
<a name="L266"></a><tt class="py-lineno">266</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; rr = RidgeRegression(X=X, y=y, k=3.14159265)</tt> </tt>
<a name="L267"></a><tt class="py-lineno">267</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; beta = np.random.rand(150, 1)</tt> </tt>
<a name="L268"></a><tt class="py-lineno">268</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(np.linalg.norm(rr.grad(beta)</tt> </tt>
<a name="L269"></a><tt class="py-lineno">269</tt>  <tt class="py-line"><tt class="py-docstring">        ...       - rr.approx_grad(beta, eps=1e-4)), 9)</tt> </tt>
<a name="L270"></a><tt class="py-lineno">270</tt>  <tt class="py-line"><tt class="py-docstring">        1.3e-08</tt> </tt>
<a name="L271"></a><tt class="py-lineno">271</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L272"></a><tt class="py-lineno">272</tt>  <tt class="py-line">        <tt class="py-name">gradOLS</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-39" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-39', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-40" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-40', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-41" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-41', 'beta', 'link-15');">beta</a></tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-42" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.T" class="py-name" href="#" onclick="return doclink('link-42', 'T', 'link-19');">T</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-43" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.T" class="py-name" href="#" onclick="return doclink('link-43', 'T', 'link-19');">T</a></tt> </tt>
<a name="L273"></a><tt class="py-lineno">273</tt>  <tt class="py-line"> </tt>
<a name="L274"></a><tt class="py-lineno">274</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L275"></a><tt class="py-lineno">275</tt>  <tt class="py-line">            <tt class="py-name">gradOLS</tt> <tt class="py-op">*=</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L276"></a><tt class="py-lineno">276</tt>  <tt class="py-line"> </tt>
<a name="L277"></a><tt class="py-lineno">277</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">0</tt><tt class="py-op">:</tt> </tt>
<a name="L278"></a><tt class="py-lineno">278</tt>  <tt class="py-line">            <tt class="py-name">gradL2</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">vstack</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">zeros</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt><tt class="py-op">,</tt> <tt class="py-number">1</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L279"></a><tt class="py-lineno">279</tt>  <tt class="py-line">                                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">*</tt> <tt id="link-44" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-44', 'beta', 'link-15');">beta</a></tt><tt class="py-op">[</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt><tt class="py-op">:</tt><tt class="py-op">,</tt> <tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L280"></a><tt class="py-lineno">280</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L281"></a><tt class="py-lineno">281</tt>  <tt class="py-line">            <tt class="py-name">gradL2</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">*</tt> <tt id="link-45" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-45', 'beta', 'link-15');">beta</a></tt> </tt>
<a name="L282"></a><tt class="py-lineno">282</tt>  <tt class="py-line"> </tt>
<a name="L283"></a><tt class="py-lineno">283</tt>  <tt class="py-line">        <tt id="link-46" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-46', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">=</tt> <tt class="py-name">gradOLS</tt> <tt class="py-op">+</tt> <tt class="py-name">gradL2</tt> </tt>
<a name="L284"></a><tt class="py-lineno">284</tt>  <tt class="py-line"> </tt>
<a name="L285"></a><tt class="py-lineno">285</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-47" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-47', 'grad', 'link-17');">grad</a></tt> </tt>
</div><a name="L286"></a><tt class="py-lineno">286</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.L"></a><div id="RidgeRegression.L-def"><a name="L287"></a><tt class="py-lineno">287</tt> <a class="py-toggle" href="#" id="RidgeRegression.L-toggle" onclick="return toggle('RidgeRegression.L');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#L">L</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.L-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.L-expanded"><a name="L288"></a><tt class="py-lineno">288</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lipschitz constant of the gradient.</tt> </tt>
<a name="L289"></a><tt class="py-lineno">289</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L290"></a><tt class="py-lineno">290</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "LipschitzContinuousGradient".</tt> </tt>
<a name="L291"></a><tt class="py-lineno">291</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L292"></a><tt class="py-lineno">292</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L293"></a><tt class="py-lineno">293</tt>  <tt class="py-line">            <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt><tt class="py-op">.</tt><tt class="py-name">svd</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">full_matrices</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-name">compute_uv</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt> </tt>
<a name="L294"></a><tt class="py-lineno">294</tt>  <tt class="py-line"> </tt>
<a name="L295"></a><tt class="py-lineno">295</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L296"></a><tt class="py-lineno">296</tt>  <tt class="py-line"> </tt>
<a name="L297"></a><tt class="py-lineno">297</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">&lt;</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">:</tt> </tt>
<a name="L298"></a><tt class="py-lineno">298</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-number">0.0</tt> </tt>
<a name="L299"></a><tt class="py-lineno">299</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L300"></a><tt class="py-lineno">300</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">min</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L301"></a><tt class="py-lineno">301</tt>  <tt class="py-line"> </tt>
<a name="L302"></a><tt class="py-lineno">302</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L303"></a><tt class="py-lineno">303</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">/=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L304"></a><tt class="py-lineno">304</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">/=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L305"></a><tt class="py-lineno">305</tt>  <tt class="py-line"> </tt>
<a name="L306"></a><tt class="py-lineno">306</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> </tt>
</div><a name="L307"></a><tt class="py-lineno">307</tt>  <tt class="py-line"> </tt>
<a name="L308"></a><tt class="py-lineno">308</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">utils</tt><tt class="py-op">.</tt><tt id="link-48" class="py-name" targets="Function parsimony.utils.utils.deprecated()=parsimony.utils.utils-module.html#deprecated"><a title="parsimony.utils.utils.deprecated" class="py-name" href="#" onclick="return doclink('link-48', 'deprecated', 'link-48');">deprecated</a></tt><tt class="py-op">(</tt><tt class="py-string">"StronglyConvex.parameter"</tt><tt class="py-op">)</tt> </tt>
<a name="RidgeRegression.lambda_min"></a><div id="RidgeRegression.lambda_min-def"><a name="L309"></a><tt class="py-lineno">309</tt> <a class="py-toggle" href="#" id="RidgeRegression.lambda_min-toggle" onclick="return toggle('RidgeRegression.lambda_min');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#lambda_min">lambda_min</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.lambda_min-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.lambda_min-expanded"><a name="L310"></a><tt class="py-lineno">310</tt>  <tt class="py-line">        <tt class="py-docstring">"""Smallest eigenvalue of the corresponding covariance matrix.</tt> </tt>
<a name="L311"></a><tt class="py-lineno">311</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L312"></a><tt class="py-lineno">312</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Eigenvalues".</tt> </tt>
<a name="L313"></a><tt class="py-lineno">313</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L314"></a><tt class="py-lineno">314</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-49" class="py-name" targets="Variable parsimony.algorithms.utils.Info.parameter=parsimony.algorithms.utils.Info-class.html#parameter,Method parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.parameter()=parsimony.functions.combinedfunctions.LinearRegressionL1L2TV-class.html#parameter,Method parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.parameter()=parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV-class.html#parameter,Method parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.parameter()=parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV-class.html#parameter,Method parsimony.functions.losses.RidgeRegression.parameter()=parsimony.functions.losses.RidgeRegression-class.html#parameter,Method parsimony.functions.penalties.RidgeSquaredError.parameter()=parsimony.functions.penalties.RidgeSquaredError-class.html#parameter,Method parsimony.functions.properties.StronglyConvex.parameter()=parsimony.functions.properties.StronglyConvex-class.html#parameter"><a title="parsimony.algorithms.utils.Info.parameter
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.parameter
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.parameter
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.parameter
parsimony.functions.losses.RidgeRegression.parameter
parsimony.functions.penalties.RidgeSquaredError.parameter
parsimony.functions.properties.StronglyConvex.parameter" class="py-name" href="#" onclick="return doclink('link-49', 'parameter', 'link-49');">parameter</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L315"></a><tt class="py-lineno">315</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.parameter"></a><div id="RidgeRegression.parameter-def"><a name="L316"></a><tt class="py-lineno">316</tt> <a class="py-toggle" href="#" id="RidgeRegression.parameter-toggle" onclick="return toggle('RidgeRegression.parameter');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#parameter">parameter</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.parameter-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.parameter-expanded"><a name="L317"></a><tt class="py-lineno">317</tt>  <tt class="py-line">        <tt class="py-docstring">"""Returns the strongly convex parameter for the function.</tt> </tt>
<a name="L318"></a><tt class="py-lineno">318</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L319"></a><tt class="py-lineno">319</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "StronglyConvex".</tt> </tt>
<a name="L320"></a><tt class="py-lineno">320</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L321"></a><tt class="py-lineno">321</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L322"></a><tt class="py-lineno">322</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
<a name="L323"></a><tt class="py-lineno">323</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-50" class="py-name"><a title="parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.L
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.L
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.L
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.L
parsimony.functions.losses.LatentVariableVariance.L
parsimony.functions.losses.LinearFunction.L
parsimony.functions.losses.LinearRegression.L
parsimony.functions.losses.LogisticRegression.L
parsimony.functions.losses.RidgeLogisticRegression.L
parsimony.functions.losses.RidgeRegression.L
parsimony.functions.multiblock.losses.LatentVariableCovariance.L
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.L
parsimony.functions.multiblock.properties.MultiblockLipschitzContinuousGradient.L
parsimony.functions.nesterov.gl.GroupLassoOverlap.L
parsimony.functions.nesterov.grouptv.GroupTotalVariation.L
parsimony.functions.nesterov.l1.L1.L
parsimony.functions.nesterov.tv.TotalVariation.L
parsimony.functions.penalties.L2Squared.L
parsimony.functions.penalties.RidgeSquaredError.L
parsimony.functions.properties.LipschitzContinuousGradient.L
parsimony.functions.properties.NesterovFunction.L" class="py-name" href="#" onclick="return doclink('link-50', 'L', 'link-31');">L</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt>  <tt class="py-comment"># Precompute</tt> </tt>
<a name="L324"></a><tt class="py-lineno">324</tt>  <tt class="py-line"> </tt>
<a name="L325"></a><tt class="py-lineno">325</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_min</tt> <tt class="py-op">+</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> </tt>
</div><a name="L326"></a><tt class="py-lineno">326</tt>  <tt class="py-line"> </tt>
<a name="RidgeRegression.step"></a><div id="RidgeRegression.step-def"><a name="L327"></a><tt class="py-lineno">327</tt> <a class="py-toggle" href="#" id="RidgeRegression.step-toggle" onclick="return toggle('RidgeRegression.step');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeRegression-class.html#step">step</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">,</tt> <tt class="py-param">index</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeRegression.step-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeRegression.step-expanded"><a name="L328"></a><tt class="py-lineno">328</tt>  <tt class="py-line">        <tt class="py-docstring">"""The step size to use in descent methods.</tt> </tt>
<a name="L329"></a><tt class="py-lineno">329</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L330"></a><tt class="py-lineno">330</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L331"></a><tt class="py-lineno">331</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L332"></a><tt class="py-lineno">332</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. The point at which to determine the step size.</tt> </tt>
<a name="L333"></a><tt class="py-lineno">333</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L334"></a><tt class="py-lineno">334</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-51" class="py-name"><a title="parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.L
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.L
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.L
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.L
parsimony.functions.losses.LatentVariableVariance.L
parsimony.functions.losses.LinearFunction.L
parsimony.functions.losses.LinearRegression.L
parsimony.functions.losses.LogisticRegression.L
parsimony.functions.losses.RidgeLogisticRegression.L
parsimony.functions.losses.RidgeRegression.L
parsimony.functions.multiblock.losses.LatentVariableCovariance.L
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.L
parsimony.functions.multiblock.properties.MultiblockLipschitzContinuousGradient.L
parsimony.functions.nesterov.gl.GroupLassoOverlap.L
parsimony.functions.nesterov.grouptv.GroupTotalVariation.L
parsimony.functions.nesterov.l1.L1.L
parsimony.functions.nesterov.tv.TotalVariation.L
parsimony.functions.penalties.L2Squared.L
parsimony.functions.penalties.RidgeSquaredError.L
parsimony.functions.properties.LipschitzContinuousGradient.L
parsimony.functions.properties.NesterovFunction.L" class="py-name" href="#" onclick="return doclink('link-51', 'L', 'link-31');">L</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L335"></a><tt class="py-lineno">335</tt>  <tt class="py-line"> </tt>
<a name="LogisticRegression"></a><div id="LogisticRegression-def"><a name="L336"></a><tt class="py-lineno">336</tt>  <tt class="py-line"> </tt>
<a name="L337"></a><tt class="py-lineno">337</tt> <a class="py-toggle" href="#" id="LogisticRegression-toggle" onclick="return toggle('LogisticRegression');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="parsimony.functions.losses.LogisticRegression-class.html">LogisticRegression</a><tt class="py-op">(</tt><tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">AtomicFunction</tt><tt class="py-op">,</tt> </tt>
<a name="L338"></a><tt class="py-lineno">338</tt>  <tt class="py-line">                         <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">Gradient</tt><tt class="py-op">,</tt> </tt>
<a name="L339"></a><tt class="py-lineno">339</tt>  <tt class="py-line">                         <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">LipschitzContinuousGradient</tt><tt class="py-op">,</tt> </tt>
<a name="L340"></a><tt class="py-lineno">340</tt>  <tt class="py-line">                         <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">StepSize</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LogisticRegression-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="LogisticRegression-expanded"><a name="L341"></a><tt class="py-lineno">341</tt>  <tt class="py-line">    <tt class="py-docstring">"""The Logistic Regression loss function.</tt> </tt>
<a name="L342"></a><tt class="py-lineno">342</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L343"></a><tt class="py-lineno">343</tt>  <tt class="py-line"><tt class="py-docstring">    (Re-weighted) Log-likelihood (cross-entropy):</tt> </tt>
<a name="L344"></a><tt class="py-lineno">344</tt>  <tt class="py-line"><tt class="py-docstring">      * f(beta) = -Sum wi (yi log(pi) + (1 &#8722; yi) log(1 &#8722; pi))</tt> </tt>
<a name="L345"></a><tt class="py-lineno">345</tt>  <tt class="py-line"><tt class="py-docstring">                = -Sum wi (yi xi' beta &#8722; log(1 + e(x_i'beta))),</tt> </tt>
<a name="L346"></a><tt class="py-lineno">346</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L347"></a><tt class="py-lineno">347</tt>  <tt class="py-line"><tt class="py-docstring">      * grad f(beta) = -Sum wi[ xi (yi - pi)] + k beta,</tt> </tt>
<a name="L348"></a><tt class="py-lineno">348</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L349"></a><tt class="py-lineno">349</tt>  <tt class="py-line"><tt class="py-docstring">    where pi = p(y=1 | xi, beta) = 1 / (1 + exp(-x_i'beta)) and wi is the</tt> </tt>
<a name="L350"></a><tt class="py-lineno">350</tt>  <tt class="py-line"><tt class="py-docstring">    weight for sample i.</tt> </tt>
<a name="L351"></a><tt class="py-lineno">351</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L352"></a><tt class="py-lineno">352</tt>  <tt class="py-line"><tt class="py-docstring">    See [Hastie 2009, p.: 102, 119 and 161, Bishop 2006 p.: 206] for details.</tt> </tt>
<a name="L353"></a><tt class="py-lineno">353</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L354"></a><tt class="py-lineno">354</tt>  <tt class="py-line"><tt class="py-docstring">    Parameters</tt> </tt>
<a name="L355"></a><tt class="py-lineno">355</tt>  <tt class="py-line"><tt class="py-docstring">    ----------</tt> </tt>
<a name="L356"></a><tt class="py-lineno">356</tt>  <tt class="py-line"><tt class="py-docstring">    X : Numpy array (n-by-p). The regressor matrix.</tt> </tt>
<a name="L357"></a><tt class="py-lineno">357</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L358"></a><tt class="py-lineno">358</tt>  <tt class="py-line"><tt class="py-docstring">    y : Numpy array (n-by-1). The regressand vector.</tt> </tt>
<a name="L359"></a><tt class="py-lineno">359</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L360"></a><tt class="py-lineno">360</tt>  <tt class="py-line"><tt class="py-docstring">    weights: Numpy array (n-by-1). The sample's weights.</tt> </tt>
<a name="L361"></a><tt class="py-lineno">361</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L362"></a><tt class="py-lineno">362</tt>  <tt class="py-line"><tt class="py-docstring">    mean : Boolean. Whether to compute the squared loss or the mean squared</tt> </tt>
<a name="L363"></a><tt class="py-lineno">363</tt>  <tt class="py-line"><tt class="py-docstring">            loss. Default is True, the mean squared loss.</tt> </tt>
<a name="L364"></a><tt class="py-lineno">364</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="LogisticRegression.__init__"></a><div id="LogisticRegression.__init__-def"><a name="L365"></a><tt class="py-lineno">365</tt> <a class="py-toggle" href="#" id="LogisticRegression.__init__-toggle" onclick="return toggle('LogisticRegression.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LogisticRegression-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">X</tt><tt class="py-op">,</tt> <tt class="py-param">y</tt><tt class="py-op">,</tt> <tt class="py-param">weights</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-param">mean</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LogisticRegression.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LogisticRegression.__init__-expanded"><a name="L366"></a><tt class="py-lineno">366</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt> <tt class="py-op">=</tt> <tt class="py-name">X</tt> </tt>
<a name="L367"></a><tt class="py-lineno">367</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">=</tt> <tt class="py-name">y</tt> </tt>
<a name="L368"></a><tt class="py-lineno">368</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">weights</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L369"></a><tt class="py-lineno">369</tt>  <tt class="py-line">            <tt class="py-comment"># TODO: Make the weights sparse.</tt> </tt>
<a name="L370"></a><tt class="py-lineno">370</tt>  <tt class="py-line">            <tt class="py-comment">#weights = np.eye(self.X.shape[0])</tt> </tt>
<a name="L371"></a><tt class="py-lineno">371</tt>  <tt class="py-line">            <tt class="py-name">weights</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">ones</tt><tt class="py-op">(</tt><tt class="py-name">y</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt class="py-name">y</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">)</tt> </tt>
<a name="L372"></a><tt class="py-lineno">372</tt>  <tt class="py-line">        <tt class="py-comment"># TODO: Allow the weight vector to be a list.</tt> </tt>
<a name="L373"></a><tt class="py-lineno">373</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt> <tt class="py-op">=</tt> <tt class="py-name">weights</tt> </tt>
<a name="L374"></a><tt class="py-lineno">374</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt> <tt class="py-op">=</tt> <tt class="py-name">bool</tt><tt class="py-op">(</tt><tt class="py-name">mean</tt><tt class="py-op">)</tt> </tt>
<a name="L375"></a><tt class="py-lineno">375</tt>  <tt class="py-line"> </tt>
<a name="L376"></a><tt class="py-lineno">376</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-52" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.CombinedFunction.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.reset
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.reset
parsimony.functions.losses.LatentVariableVariance.reset
parsimony.functions.losses.LinearFunction.reset
parsimony.functions.losses.LinearRegression.reset
parsimony.functions.losses.LogisticRegression.reset
parsimony.functions.losses.RidgeLogisticRegression.reset
parsimony.functions.losses.RidgeRegression.reset
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.reset
parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset
parsimony.functions.multiblock.losses.LatentVariableCovariance.reset
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.reset
parsimony.functions.nesterov.gl.GroupLassoOverlap.reset
parsimony.functions.nesterov.grouptv.GroupTotalVariation.reset
parsimony.functions.nesterov.l1tv.L1TV.reset
parsimony.functions.nesterov.tv.TotalVariation.reset
parsimony.functions.penalties.LinearVariableConstraint.reset
parsimony.functions.penalties.RGCCAConstraint.reset
parsimony.functions.penalties.RidgeSquaredError.reset
parsimony.functions.penalties.ZeroFunction.reset
parsimony.functions.properties.Function.reset" class="py-name" href="#" onclick="return doclink('link-52', 'reset', 'link-12');">reset</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L377"></a><tt class="py-lineno">377</tt>  <tt class="py-line"> </tt>
<a name="LogisticRegression.reset"></a><div id="LogisticRegression.reset-def"><a name="L378"></a><tt class="py-lineno">378</tt> <a class="py-toggle" href="#" id="LogisticRegression.reset-toggle" onclick="return toggle('LogisticRegression.reset');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LogisticRegression-class.html#reset">reset</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LogisticRegression.reset-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LogisticRegression.reset-expanded"><a name="L379"></a><tt class="py-lineno">379</tt>  <tt class="py-line">        <tt class="py-docstring">"""Free any cached computations from previous use of this Function.</tt> </tt>
<a name="L380"></a><tt class="py-lineno">380</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L381"></a><tt class="py-lineno">381</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L382"></a><tt class="py-lineno">382</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L383"></a><tt class="py-lineno">383</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L384"></a><tt class="py-lineno">384</tt>  <tt class="py-line"> </tt>
<a name="LogisticRegression.f"></a><div id="LogisticRegression.f-def"><a name="L385"></a><tt class="py-lineno">385</tt> <a class="py-toggle" href="#" id="LogisticRegression.f-toggle" onclick="return toggle('LogisticRegression.f');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LogisticRegression-class.html#f">f</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LogisticRegression.f-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LogisticRegression.f-expanded"><a name="L386"></a><tt class="py-lineno">386</tt>  <tt class="py-line">        <tt class="py-docstring">"""Function value at the point beta.</tt> </tt>
<a name="L387"></a><tt class="py-lineno">387</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L388"></a><tt class="py-lineno">388</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L389"></a><tt class="py-lineno">389</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L390"></a><tt class="py-lineno">390</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L391"></a><tt class="py-lineno">391</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L392"></a><tt class="py-lineno">392</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. Regression coefficient vector. The point at which</tt> </tt>
<a name="L393"></a><tt class="py-lineno">393</tt>  <tt class="py-line"><tt class="py-docstring">                to evaluate the function.</tt> </tt>
<a name="L394"></a><tt class="py-lineno">394</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L395"></a><tt class="py-lineno">395</tt>  <tt class="py-line">        <tt class="py-name">Xbeta</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-53" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-53', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-54" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-54', 'beta', 'link-15');">beta</a></tt><tt class="py-op">)</tt> </tt>
<a name="L396"></a><tt class="py-lineno">396</tt>  <tt class="py-line">        <tt class="py-name">negloglike</tt> <tt class="py-op">=</tt> <tt class="py-op">-</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt> <tt class="py-op">*</tt> </tt>
<a name="L397"></a><tt class="py-lineno">397</tt>  <tt class="py-line">                                <tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">*</tt> <tt class="py-name">Xbeta</tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">log</tt><tt class="py-op">(</tt><tt class="py-number">1</tt> <tt class="py-op">+</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">exp</tt><tt class="py-op">(</tt><tt class="py-name">Xbeta</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L398"></a><tt class="py-lineno">398</tt>  <tt class="py-line"> </tt>
<a name="L399"></a><tt class="py-lineno">399</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L400"></a><tt class="py-lineno">400</tt>  <tt class="py-line">            <tt class="py-name">negloglike</tt> <tt class="py-op">/=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L401"></a><tt class="py-lineno">401</tt>  <tt class="py-line"> </tt>
<a name="L402"></a><tt class="py-lineno">402</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">negloglike</tt> </tt>
</div><a name="L403"></a><tt class="py-lineno">403</tt>  <tt class="py-line"> </tt>
<a name="LogisticRegression.grad"></a><div id="LogisticRegression.grad-def"><a name="L404"></a><tt class="py-lineno">404</tt> <a class="py-toggle" href="#" id="LogisticRegression.grad-toggle" onclick="return toggle('LogisticRegression.grad');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LogisticRegression-class.html#grad">grad</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LogisticRegression.grad-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LogisticRegression.grad-expanded"><a name="L405"></a><tt class="py-lineno">405</tt>  <tt class="py-line">        <tt class="py-docstring">"""Gradient of the function at beta.</tt> </tt>
<a name="L406"></a><tt class="py-lineno">406</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L407"></a><tt class="py-lineno">407</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Gradient".</tt> </tt>
<a name="L408"></a><tt class="py-lineno">408</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L409"></a><tt class="py-lineno">409</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L410"></a><tt class="py-lineno">410</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L411"></a><tt class="py-lineno">411</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. The point at which to evaluate the gradient.</tt> </tt>
<a name="L412"></a><tt class="py-lineno">412</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L413"></a><tt class="py-lineno">413</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L414"></a><tt class="py-lineno">414</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L415"></a><tt class="py-lineno">415</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L416"></a><tt class="py-lineno">416</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import LogisticRegression</tt> </tt>
<a name="L417"></a><tt class="py-lineno">417</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L418"></a><tt class="py-lineno">418</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L419"></a><tt class="py-lineno">419</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(100, 150)</tt> </tt>
<a name="L420"></a><tt class="py-lineno">420</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y = np.random.randint(0, 2, (100, 1))</tt> </tt>
<a name="L421"></a><tt class="py-lineno">421</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; lr = LogisticRegression(X=X, y=y, mean=True)</tt> </tt>
<a name="L422"></a><tt class="py-lineno">422</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; beta = np.random.rand(150, 1)</tt> </tt>
<a name="L423"></a><tt class="py-lineno">423</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(np.linalg.norm(lr.grad(beta)</tt> </tt>
<a name="L424"></a><tt class="py-lineno">424</tt>  <tt class="py-line"><tt class="py-docstring">        ...       - lr.approx_grad(beta, eps=1e-4)), 10)</tt> </tt>
<a name="L425"></a><tt class="py-lineno">425</tt>  <tt class="py-line"><tt class="py-docstring">        4e-10</tt> </tt>
<a name="L426"></a><tt class="py-lineno">426</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L427"></a><tt class="py-lineno">427</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L428"></a><tt class="py-lineno">428</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(100, 150)</tt> </tt>
<a name="L429"></a><tt class="py-lineno">429</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y = np.random.randint(0, 2, (100, 1))</tt> </tt>
<a name="L430"></a><tt class="py-lineno">430</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; lr = LogisticRegression(X=X, y=y, mean=False)</tt> </tt>
<a name="L431"></a><tt class="py-lineno">431</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; beta = np.random.rand(150, 1)</tt> </tt>
<a name="L432"></a><tt class="py-lineno">432</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(np.linalg.norm(lr.grad(beta)</tt> </tt>
<a name="L433"></a><tt class="py-lineno">433</tt>  <tt class="py-line"><tt class="py-docstring">        ...       - lr.approx_grad(beta, eps=1e-4)), 9)</tt> </tt>
<a name="L434"></a><tt class="py-lineno">434</tt>  <tt class="py-line"><tt class="py-docstring">        3.9e-08</tt> </tt>
<a name="L435"></a><tt class="py-lineno">435</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L436"></a><tt class="py-lineno">436</tt>  <tt class="py-line">        <tt class="py-name">Xbeta</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-55" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-55', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-56" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-56', 'beta', 'link-15');">beta</a></tt><tt class="py-op">)</tt> </tt>
<a name="L437"></a><tt class="py-lineno">437</tt>  <tt class="py-line"><tt class="py-comment">#        pi = 1.0 / (1.0 + np.exp(-Xbeta))</tt> </tt>
<a name="L438"></a><tt class="py-lineno">438</tt>  <tt class="py-line">        <tt class="py-name">pi</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">reciprocal</tt><tt class="py-op">(</tt><tt class="py-number">1.0</tt> <tt class="py-op">+</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">exp</tt><tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-name">Xbeta</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L439"></a><tt class="py-lineno">439</tt>  <tt class="py-line"> </tt>
<a name="L440"></a><tt class="py-lineno">440</tt>  <tt class="py-line">        <tt id="link-57" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-57', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">=</tt> <tt class="py-op">-</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-58" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-58', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt id="link-59" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.T" class="py-name" href="#" onclick="return doclink('link-59', 'T', 'link-19');">T</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt> <tt class="py-op">*</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">-</tt> <tt class="py-name">pi</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L441"></a><tt class="py-lineno">441</tt>  <tt class="py-line"> </tt>
<a name="L442"></a><tt class="py-lineno">442</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L443"></a><tt class="py-lineno">443</tt>  <tt class="py-line">            <tt id="link-60" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-60', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">*=</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L444"></a><tt class="py-lineno">444</tt>  <tt class="py-line"> </tt>
<a name="L445"></a><tt class="py-lineno">445</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-61" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-61', 'grad', 'link-17');">grad</a></tt> </tt>
</div><a name="L446"></a><tt class="py-lineno">446</tt>  <tt class="py-line"> </tt>
<a name="LogisticRegression.L"></a><div id="LogisticRegression.L-def"><a name="L447"></a><tt class="py-lineno">447</tt> <a class="py-toggle" href="#" id="LogisticRegression.L-toggle" onclick="return toggle('LogisticRegression.L');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LogisticRegression-class.html#L">L</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LogisticRegression.L-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LogisticRegression.L-expanded"><a name="L448"></a><tt class="py-lineno">448</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lipschitz constant of the gradient.</tt> </tt>
<a name="L449"></a><tt class="py-lineno">449</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L450"></a><tt class="py-lineno">450</tt>  <tt class="py-line"><tt class="py-docstring">        Returns the maximum eigenvalue of (1 / 4) * X'WX.</tt> </tt>
<a name="L451"></a><tt class="py-lineno">451</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L452"></a><tt class="py-lineno">452</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "LipschitzContinuousGradient".</tt> </tt>
<a name="L453"></a><tt class="py-lineno">453</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L454"></a><tt class="py-lineno">454</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L455"></a><tt class="py-lineno">455</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L456"></a><tt class="py-lineno">456</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L457"></a><tt class="py-lineno">457</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import LogisticRegression</tt> </tt>
<a name="L458"></a><tt class="py-lineno">458</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L459"></a><tt class="py-lineno">459</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L460"></a><tt class="py-lineno">460</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(10, 15)</tt> </tt>
<a name="L461"></a><tt class="py-lineno">461</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y = np.random.randint(0, 2, (10, 1))</tt> </tt>
<a name="L462"></a><tt class="py-lineno">462</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; lr = LogisticRegression(X=X, y=y, mean=True)</tt> </tt>
<a name="L463"></a><tt class="py-lineno">463</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L = lr.L()</tt> </tt>
<a name="L464"></a><tt class="py-lineno">464</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L_ = lr.approx_L((15, 1), 10000)</tt> </tt>
<a name="L465"></a><tt class="py-lineno">465</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L &gt;= L_</tt> </tt>
<a name="L466"></a><tt class="py-lineno">466</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L467"></a><tt class="py-lineno">467</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round((L - L_) / L, 15)</tt> </tt>
<a name="L468"></a><tt class="py-lineno">468</tt>  <tt class="py-line"><tt class="py-docstring">        0.45110910457988</tt> </tt>
<a name="L469"></a><tt class="py-lineno">469</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; lr = LogisticRegression(X=X, y=y, mean=False)</tt> </tt>
<a name="L470"></a><tt class="py-lineno">470</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L = lr.L()</tt> </tt>
<a name="L471"></a><tt class="py-lineno">471</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L_ = lr.approx_L((15, 1), 10000)</tt> </tt>
<a name="L472"></a><tt class="py-lineno">472</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L &gt;= L_</tt> </tt>
<a name="L473"></a><tt class="py-lineno">473</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L474"></a><tt class="py-lineno">474</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round((L - L_) / L, 13)</tt> </tt>
<a name="L475"></a><tt class="py-lineno">475</tt>  <tt class="py-line"><tt class="py-docstring">        0.430306683612</tt> </tt>
<a name="L476"></a><tt class="py-lineno">476</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L477"></a><tt class="py-lineno">477</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">==</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L478"></a><tt class="py-lineno">478</tt>  <tt class="py-line">            <tt class="py-comment"># pi(x) * (1 - pi(x)) &lt;= 0.25 = 0.5 * 0.5</tt> </tt>
<a name="L479"></a><tt class="py-lineno">479</tt>  <tt class="py-line">            <tt class="py-name">PWX</tt> <tt class="py-op">=</tt> <tt class="py-number">0.5</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sqrt</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt> </tt>
<a name="L480"></a><tt class="py-lineno">480</tt>  <tt class="py-line">            <tt class="py-comment"># TODO: Use FastSVD for speedup!</tt> </tt>
<a name="L481"></a><tt class="py-lineno">481</tt>  <tt class="py-line">            <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt><tt class="py-op">.</tt><tt class="py-name">svd</tt><tt class="py-op">(</tt><tt class="py-name">PWX</tt><tt class="py-op">,</tt> <tt class="py-name">full_matrices</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-name">compute_uv</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt> </tt>
<a name="L482"></a><tt class="py-lineno">482</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt>  <tt class="py-comment"># TODO: CHECK</tt> </tt>
<a name="L483"></a><tt class="py-lineno">483</tt>  <tt class="py-line"> </tt>
<a name="L484"></a><tt class="py-lineno">484</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L485"></a><tt class="py-lineno">485</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">/=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L486"></a><tt class="py-lineno">486</tt>  <tt class="py-line"> </tt>
<a name="L487"></a><tt class="py-lineno">487</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> </tt>
</div><a name="L488"></a><tt class="py-lineno">488</tt>  <tt class="py-line"> </tt>
<a name="LogisticRegression.step"></a><div id="LogisticRegression.step-def"><a name="L489"></a><tt class="py-lineno">489</tt> <a class="py-toggle" href="#" id="LogisticRegression.step-toggle" onclick="return toggle('LogisticRegression.step');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LogisticRegression-class.html#step">step</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">,</tt> <tt class="py-param">index</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LogisticRegression.step-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LogisticRegression.step-expanded"><a name="L490"></a><tt class="py-lineno">490</tt>  <tt class="py-line">        <tt class="py-docstring">"""The step size to use in descent methods.</tt> </tt>
<a name="L491"></a><tt class="py-lineno">491</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L492"></a><tt class="py-lineno">492</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L493"></a><tt class="py-lineno">493</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L494"></a><tt class="py-lineno">494</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. The point at which to determine the step size.</tt> </tt>
<a name="L495"></a><tt class="py-lineno">495</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L496"></a><tt class="py-lineno">496</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-62" class="py-name"><a title="parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.L
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.L
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.L
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.L
parsimony.functions.losses.LatentVariableVariance.L
parsimony.functions.losses.LinearFunction.L
parsimony.functions.losses.LinearRegression.L
parsimony.functions.losses.LogisticRegression.L
parsimony.functions.losses.RidgeLogisticRegression.L
parsimony.functions.losses.RidgeRegression.L
parsimony.functions.multiblock.losses.LatentVariableCovariance.L
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.L
parsimony.functions.multiblock.properties.MultiblockLipschitzContinuousGradient.L
parsimony.functions.nesterov.gl.GroupLassoOverlap.L
parsimony.functions.nesterov.grouptv.GroupTotalVariation.L
parsimony.functions.nesterov.l1.L1.L
parsimony.functions.nesterov.tv.TotalVariation.L
parsimony.functions.penalties.L2Squared.L
parsimony.functions.penalties.RidgeSquaredError.L
parsimony.functions.properties.LipschitzContinuousGradient.L
parsimony.functions.properties.NesterovFunction.L" class="py-name" href="#" onclick="return doclink('link-62', 'L', 'link-31');">L</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L497"></a><tt class="py-lineno">497</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression"></a><div id="RidgeLogisticRegression-def"><a name="L498"></a><tt class="py-lineno">498</tt>  <tt class="py-line"> </tt>
<a name="L499"></a><tt class="py-lineno">499</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression-toggle" onclick="return toggle('RidgeLogisticRegression');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html">RidgeLogisticRegression</a><tt class="py-op">(</tt><tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">CompositeFunction</tt><tt class="py-op">,</tt> </tt>
<a name="L500"></a><tt class="py-lineno">500</tt>  <tt class="py-line">                              <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">Gradient</tt><tt class="py-op">,</tt> </tt>
<a name="L501"></a><tt class="py-lineno">501</tt>  <tt class="py-line">                              <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">LipschitzContinuousGradient</tt><tt class="py-op">,</tt> </tt>
<a name="L502"></a><tt class="py-lineno">502</tt>  <tt class="py-line">                              <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">StepSize</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="RidgeLogisticRegression-expanded"><a name="L503"></a><tt class="py-lineno">503</tt>  <tt class="py-line">    <tt class="py-docstring">"""The Logistic Regression loss function with a squared L2 penalty.</tt> </tt>
<a name="L504"></a><tt class="py-lineno">504</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L505"></a><tt class="py-lineno">505</tt>  <tt class="py-line"><tt class="py-docstring">    Ridge (re-weighted) log-likelihood (cross-entropy):</tt> </tt>
<a name="L506"></a><tt class="py-lineno">506</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L507"></a><tt class="py-lineno">507</tt>  <tt class="py-line"><tt class="py-docstring">    * f(beta) = -loglik + k/2 * ||beta||^2_2</tt> </tt>
<a name="L508"></a><tt class="py-lineno">508</tt>  <tt class="py-line"><tt class="py-docstring">              = -Sum wi (yi log(pi) + (1 &#8722; yi) log(1 &#8722; pi)) + k/2*||beta||^2_2</tt> </tt>
<a name="L509"></a><tt class="py-lineno">509</tt>  <tt class="py-line"><tt class="py-docstring">              = -Sum wi (yi xi' beta &#8722; log(1 + e(xi' beta))) + k/2*||beta||^2_2</tt> </tt>
<a name="L510"></a><tt class="py-lineno">510</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L511"></a><tt class="py-lineno">511</tt>  <tt class="py-line"><tt class="py-docstring">    * grad f(beta) = -Sum wi[ xi (yi - pi)] + k beta</tt> </tt>
<a name="L512"></a><tt class="py-lineno">512</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L513"></a><tt class="py-lineno">513</tt>  <tt class="py-line"><tt class="py-docstring">    pi = p(y=1|xi, beta) = 1 / (1 + exp(-xi' beta))</tt> </tt>
<a name="L514"></a><tt class="py-lineno">514</tt>  <tt class="py-line"><tt class="py-docstring">    wi: sample i weight</tt> </tt>
<a name="L515"></a><tt class="py-lineno">515</tt>  <tt class="py-line"><tt class="py-docstring">    [Hastie 2009, p.: 102, 119 and 161, Bishop 2006 p.: 206]</tt> </tt>
<a name="L516"></a><tt class="py-lineno">516</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="RidgeLogisticRegression.__init__"></a><div id="RidgeLogisticRegression.__init__-def"><a name="L517"></a><tt class="py-lineno">517</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.__init__-toggle" onclick="return toggle('RidgeLogisticRegression.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">X</tt><tt class="py-op">,</tt> <tt class="py-param">y</tt><tt class="py-op">,</tt> <tt class="py-param">k</tt><tt class="py-op">=</tt><tt class="py-number">0.0</tt><tt class="py-op">,</tt> <tt class="py-param">weights</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-param">penalty_start</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-param">mean</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.__init__-expanded"><a name="L518"></a><tt class="py-lineno">518</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L519"></a><tt class="py-lineno">519</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L520"></a><tt class="py-lineno">520</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L521"></a><tt class="py-lineno">521</tt>  <tt class="py-line"><tt class="py-docstring">        X : Numpy array (n-by-p). The regressor matrix. Training vectors, where</tt> </tt>
<a name="L522"></a><tt class="py-lineno">522</tt>  <tt class="py-line"><tt class="py-docstring">                n is the number of samples and p is the number of features.</tt> </tt>
<a name="L523"></a><tt class="py-lineno">523</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L524"></a><tt class="py-lineno">524</tt>  <tt class="py-line"><tt class="py-docstring">        y : Numpy array (n-by-1). The regressand vector. Target values (class</tt> </tt>
<a name="L525"></a><tt class="py-lineno">525</tt>  <tt class="py-line"><tt class="py-docstring">                labels in classification).</tt> </tt>
<a name="L526"></a><tt class="py-lineno">526</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L527"></a><tt class="py-lineno">527</tt>  <tt class="py-line"><tt class="py-docstring">        k : Non-negative float. The ridge parameter.</tt> </tt>
<a name="L528"></a><tt class="py-lineno">528</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L529"></a><tt class="py-lineno">529</tt>  <tt class="py-line"><tt class="py-docstring">        weights: Numpy array (n-by-1). The sample's weights.</tt> </tt>
<a name="L530"></a><tt class="py-lineno">530</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L531"></a><tt class="py-lineno">531</tt>  <tt class="py-line"><tt class="py-docstring">        penalty_start : Non-negative integer. The number of columns, variables</tt> </tt>
<a name="L532"></a><tt class="py-lineno">532</tt>  <tt class="py-line"><tt class="py-docstring">                etc., to except from penalisation. Equivalently, the first</tt> </tt>
<a name="L533"></a><tt class="py-lineno">533</tt>  <tt class="py-line"><tt class="py-docstring">                index to be penalised. Default is 0, all columns are included.</tt> </tt>
<a name="L534"></a><tt class="py-lineno">534</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L535"></a><tt class="py-lineno">535</tt>  <tt class="py-line"><tt class="py-docstring">        mean : Boolean. Whether to compute the mean loss or not. Default is</tt> </tt>
<a name="L536"></a><tt class="py-lineno">536</tt>  <tt class="py-line"><tt class="py-docstring">                True, the mean loss is computed.</tt> </tt>
<a name="L537"></a><tt class="py-lineno">537</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L538"></a><tt class="py-lineno">538</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt> <tt class="py-op">=</tt> <tt class="py-name">X</tt> </tt>
<a name="L539"></a><tt class="py-lineno">539</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">=</tt> <tt class="py-name">y</tt> </tt>
<a name="L540"></a><tt class="py-lineno">540</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">=</tt> <tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-number">0.0</tt><tt class="py-op">,</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L541"></a><tt class="py-lineno">541</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">weights</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L542"></a><tt class="py-lineno">542</tt>  <tt class="py-line">            <tt class="py-name">weights</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">ones</tt><tt class="py-op">(</tt><tt class="py-name">y</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">)</tt>  <tt class="py-comment"># .reshape(y.shape)</tt> </tt>
<a name="L543"></a><tt class="py-lineno">543</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt> <tt class="py-op">=</tt> <tt class="py-name">weights</tt> </tt>
<a name="L544"></a><tt class="py-lineno">544</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt> <tt class="py-op">=</tt> <tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-name">int</tt><tt class="py-op">(</tt><tt class="py-name">penalty_start</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L545"></a><tt class="py-lineno">545</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt> <tt class="py-op">=</tt> <tt class="py-name">bool</tt><tt class="py-op">(</tt><tt class="py-name">mean</tt><tt class="py-op">)</tt> </tt>
<a name="L546"></a><tt class="py-lineno">546</tt>  <tt class="py-line"> </tt>
<a name="L547"></a><tt class="py-lineno">547</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-63" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.CombinedFunction.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.reset
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.reset
parsimony.functions.losses.LatentVariableVariance.reset
parsimony.functions.losses.LinearFunction.reset
parsimony.functions.losses.LinearRegression.reset
parsimony.functions.losses.LogisticRegression.reset
parsimony.functions.losses.RidgeLogisticRegression.reset
parsimony.functions.losses.RidgeRegression.reset
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.reset
parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset
parsimony.functions.multiblock.losses.LatentVariableCovariance.reset
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.reset
parsimony.functions.nesterov.gl.GroupLassoOverlap.reset
parsimony.functions.nesterov.grouptv.GroupTotalVariation.reset
parsimony.functions.nesterov.l1tv.L1TV.reset
parsimony.functions.nesterov.tv.TotalVariation.reset
parsimony.functions.penalties.LinearVariableConstraint.reset
parsimony.functions.penalties.RGCCAConstraint.reset
parsimony.functions.penalties.RidgeSquaredError.reset
parsimony.functions.penalties.ZeroFunction.reset
parsimony.functions.properties.Function.reset" class="py-name" href="#" onclick="return doclink('link-63', 'reset', 'link-12');">reset</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L548"></a><tt class="py-lineno">548</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression.reset"></a><div id="RidgeLogisticRegression.reset-def"><a name="L549"></a><tt class="py-lineno">549</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.reset-toggle" onclick="return toggle('RidgeLogisticRegression.reset');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#reset">reset</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.reset-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.reset-expanded"><a name="L550"></a><tt class="py-lineno">550</tt>  <tt class="py-line">        <tt class="py-docstring">"""Free any cached computations from previous use of this Function.</tt> </tt>
<a name="L551"></a><tt class="py-lineno">551</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L552"></a><tt class="py-lineno">552</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L553"></a><tt class="py-lineno">553</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L554"></a><tt class="py-lineno">554</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L555"></a><tt class="py-lineno">555</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression.f"></a><div id="RidgeLogisticRegression.f-def"><a name="L556"></a><tt class="py-lineno">556</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.f-toggle" onclick="return toggle('RidgeLogisticRegression.f');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#f">f</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.f-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.f-expanded"><a name="L557"></a><tt class="py-lineno">557</tt>  <tt class="py-line">        <tt class="py-docstring">"""Function value of Logistic regression at beta.</tt> </tt>
<a name="L558"></a><tt class="py-lineno">558</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L559"></a><tt class="py-lineno">559</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L560"></a><tt class="py-lineno">560</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L561"></a><tt class="py-lineno">561</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. Regression coefficient vector. The point at which</tt> </tt>
<a name="L562"></a><tt class="py-lineno">562</tt>  <tt class="py-line"><tt class="py-docstring">                to evaluate the function.</tt> </tt>
<a name="L563"></a><tt class="py-lineno">563</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L564"></a><tt class="py-lineno">564</tt>  <tt class="py-line">        <tt class="py-comment"># TODO check the correctness of the re-weighted loglike</tt> </tt>
<a name="L565"></a><tt class="py-lineno">565</tt>  <tt class="py-line">        <tt class="py-name">Xbeta</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-64" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-64', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-65" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-65', 'beta', 'link-15');">beta</a></tt><tt class="py-op">)</tt> </tt>
<a name="L566"></a><tt class="py-lineno">566</tt>  <tt class="py-line">        <tt class="py-name">negloglike</tt> <tt class="py-op">=</tt> <tt class="py-op">-</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt> <tt class="py-op">*</tt> </tt>
<a name="L567"></a><tt class="py-lineno">567</tt>  <tt class="py-line">                             <tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">*</tt> <tt class="py-name">Xbeta</tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">log</tt><tt class="py-op">(</tt><tt class="py-number">1</tt> <tt class="py-op">+</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">exp</tt><tt class="py-op">(</tt><tt class="py-name">Xbeta</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L568"></a><tt class="py-lineno">568</tt>  <tt class="py-line"> </tt>
<a name="L569"></a><tt class="py-lineno">569</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L570"></a><tt class="py-lineno">570</tt>  <tt class="py-line">            <tt class="py-name">negloglike</tt> <tt class="py-op">*=</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L571"></a><tt class="py-lineno">571</tt>  <tt class="py-line"> </tt>
<a name="L572"></a><tt class="py-lineno">572</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">0</tt><tt class="py-op">:</tt> </tt>
<a name="L573"></a><tt class="py-lineno">573</tt>  <tt class="py-line">            <tt class="py-name">beta_</tt> <tt class="py-op">=</tt> <tt id="link-66" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-66', 'beta', 'link-15');">beta</a></tt><tt class="py-op">[</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt><tt class="py-op">:</tt><tt class="py-op">,</tt> <tt class="py-op">:</tt><tt class="py-op">]</tt> </tt>
<a name="L574"></a><tt class="py-lineno">574</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L575"></a><tt class="py-lineno">575</tt>  <tt class="py-line">            <tt class="py-name">beta_</tt> <tt class="py-op">=</tt> <tt id="link-67" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-67', 'beta', 'link-15');">beta</a></tt> </tt>
<a name="L576"></a><tt class="py-lineno">576</tt>  <tt class="py-line"> </tt>
<a name="L577"></a><tt class="py-lineno">577</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">negloglike</tt> <tt class="py-op">+</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">/</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-name">beta_</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt><tt class="py-op">)</tt> </tt>
</div><a name="L578"></a><tt class="py-lineno">578</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression.grad"></a><div id="RidgeLogisticRegression.grad-def"><a name="L579"></a><tt class="py-lineno">579</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.grad-toggle" onclick="return toggle('RidgeLogisticRegression.grad');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#grad">grad</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.grad-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.grad-expanded"><a name="L580"></a><tt class="py-lineno">580</tt>  <tt class="py-line">        <tt class="py-docstring">"""Gradient of the function at beta.</tt> </tt>
<a name="L581"></a><tt class="py-lineno">581</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L582"></a><tt class="py-lineno">582</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Gradient".</tt> </tt>
<a name="L583"></a><tt class="py-lineno">583</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L584"></a><tt class="py-lineno">584</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L585"></a><tt class="py-lineno">585</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L586"></a><tt class="py-lineno">586</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. The point at which to evaluate the gradient.</tt> </tt>
<a name="L587"></a><tt class="py-lineno">587</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L588"></a><tt class="py-lineno">588</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L589"></a><tt class="py-lineno">589</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L590"></a><tt class="py-lineno">590</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L591"></a><tt class="py-lineno">591</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import RidgeLogisticRegression</tt> </tt>
<a name="L592"></a><tt class="py-lineno">592</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L593"></a><tt class="py-lineno">593</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L594"></a><tt class="py-lineno">594</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(100, 150)</tt> </tt>
<a name="L595"></a><tt class="py-lineno">595</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y = np.random.rand(100, 1)</tt> </tt>
<a name="L596"></a><tt class="py-lineno">596</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y[y &lt; 0.5] = 0.0</tt> </tt>
<a name="L597"></a><tt class="py-lineno">597</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y[y &gt;= 0.5] = 1.0</tt> </tt>
<a name="L598"></a><tt class="py-lineno">598</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; rr = RidgeLogisticRegression(X=X, y=y, k=2.71828182, mean=True)</tt> </tt>
<a name="L599"></a><tt class="py-lineno">599</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; beta = np.random.rand(150, 1)</tt> </tt>
<a name="L600"></a><tt class="py-lineno">600</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(np.linalg.norm(rr.grad(beta)</tt> </tt>
<a name="L601"></a><tt class="py-lineno">601</tt>  <tt class="py-line"><tt class="py-docstring">        ...       - rr.approx_grad(beta, eps=1e-4)), 11) &lt; 1e-9</tt> </tt>
<a name="L602"></a><tt class="py-lineno">602</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L603"></a><tt class="py-lineno">603</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L604"></a><tt class="py-lineno">604</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L605"></a><tt class="py-lineno">605</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(100, 150)</tt> </tt>
<a name="L606"></a><tt class="py-lineno">606</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y = np.random.rand(100, 1)</tt> </tt>
<a name="L607"></a><tt class="py-lineno">607</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y[y &lt; 0.5] = 0.0</tt> </tt>
<a name="L608"></a><tt class="py-lineno">608</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; y[y &gt;= 0.5] = 1.0</tt> </tt>
<a name="L609"></a><tt class="py-lineno">609</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; rr = RidgeLogisticRegression(X=X, y=y, k=2.71828182, mean=False)</tt> </tt>
<a name="L610"></a><tt class="py-lineno">610</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; beta = np.random.rand(150, 1)</tt> </tt>
<a name="L611"></a><tt class="py-lineno">611</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.linalg.norm(rr.grad(beta)</tt> </tt>
<a name="L612"></a><tt class="py-lineno">612</tt>  <tt class="py-line"><tt class="py-docstring">        ...                - rr.approx_grad(beta, eps=1e-4)) &lt; 5e-8</tt> </tt>
<a name="L613"></a><tt class="py-lineno">613</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L614"></a><tt class="py-lineno">614</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L615"></a><tt class="py-lineno">615</tt>  <tt class="py-line">        <tt class="py-name">Xbeta</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-68" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-68', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt id="link-69" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-69', 'beta', 'link-15');">beta</a></tt><tt class="py-op">)</tt> </tt>
<a name="L616"></a><tt class="py-lineno">616</tt>  <tt class="py-line"><tt class="py-comment">#        pi = 1.0 / (1.0 + np.exp(-Xbeta))</tt> </tt>
<a name="L617"></a><tt class="py-lineno">617</tt>  <tt class="py-line">        <tt class="py-name">pi</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">reciprocal</tt><tt class="py-op">(</tt><tt class="py-number">1.0</tt> <tt class="py-op">+</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">exp</tt><tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-name">Xbeta</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L618"></a><tt class="py-lineno">618</tt>  <tt class="py-line"> </tt>
<a name="L619"></a><tt class="py-lineno">619</tt>  <tt class="py-line">        <tt id="link-70" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-70', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">=</tt> <tt class="py-op">-</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-71" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-71', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt id="link-72" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.T" class="py-name" href="#" onclick="return doclink('link-72', 'T', 'link-19');">T</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt> <tt class="py-op">*</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">y</tt> <tt class="py-op">-</tt> <tt class="py-name">pi</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L620"></a><tt class="py-lineno">620</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L621"></a><tt class="py-lineno">621</tt>  <tt class="py-line">            <tt id="link-73" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-73', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">*=</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L622"></a><tt class="py-lineno">622</tt>  <tt class="py-line"> </tt>
<a name="L623"></a><tt class="py-lineno">623</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt> <tt class="py-op">&gt;</tt> <tt class="py-number">0</tt><tt class="py-op">:</tt> </tt>
<a name="L624"></a><tt class="py-lineno">624</tt>  <tt class="py-line">            <tt class="py-name">gradL2</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">vstack</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">zeros</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt><tt class="py-op">,</tt> <tt class="py-number">1</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L625"></a><tt class="py-lineno">625</tt>  <tt class="py-line">                                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">*</tt> <tt id="link-74" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-74', 'beta', 'link-15');">beta</a></tt><tt class="py-op">[</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">penalty_start</tt><tt class="py-op">:</tt><tt class="py-op">,</tt> <tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L626"></a><tt class="py-lineno">626</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L627"></a><tt class="py-lineno">627</tt>  <tt class="py-line">            <tt class="py-name">gradL2</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt> <tt class="py-op">*</tt> <tt id="link-75" class="py-name"><a title="parsimony.algorithms.utils.Info.beta
parsimony.datasets.simulate.beta
parsimony.utils.stats.beta" class="py-name" href="#" onclick="return doclink('link-75', 'beta', 'link-15');">beta</a></tt> </tt>
<a name="L628"></a><tt class="py-lineno">628</tt>  <tt class="py-line"> </tt>
<a name="L629"></a><tt class="py-lineno">629</tt>  <tt class="py-line">        <tt id="link-76" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-76', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">=</tt> <tt id="link-77" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-77', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">+</tt> <tt class="py-name">gradL2</tt> </tt>
<a name="L630"></a><tt class="py-lineno">630</tt>  <tt class="py-line"> </tt>
<a name="L631"></a><tt class="py-lineno">631</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-78" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-78', 'grad', 'link-17');">grad</a></tt> </tt>
</div><a name="L632"></a><tt class="py-lineno">632</tt>  <tt class="py-line"> </tt>
<a name="L633"></a><tt class="py-lineno">633</tt>  <tt class="py-line"><tt class="py-comment">#        return -np.dot(self.X.T,</tt> </tt>
<a name="L634"></a><tt class="py-lineno">634</tt>  <tt class="py-line"><tt class="py-comment">#                       np.dot(self.W, (self.y - pi))) \</tt> </tt>
<a name="L635"></a><tt class="py-lineno">635</tt>  <tt class="py-line"><tt class="py-comment">#                       + self.k * beta</tt> </tt>
<a name="L636"></a><tt class="py-lineno">636</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression.L"></a><div id="RidgeLogisticRegression.L-def"><a name="L637"></a><tt class="py-lineno">637</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.L-toggle" onclick="return toggle('RidgeLogisticRegression.L');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#L">L</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.L-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.L-expanded"><a name="L638"></a><tt class="py-lineno">638</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lipschitz constant of the gradient.</tt> </tt>
<a name="L639"></a><tt class="py-lineno">639</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L640"></a><tt class="py-lineno">640</tt>  <tt class="py-line"><tt class="py-docstring">        Returns the maximum eigenvalue of (1 / 4) * X'WX.</tt> </tt>
<a name="L641"></a><tt class="py-lineno">641</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L642"></a><tt class="py-lineno">642</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "LipschitzContinuousGradient".</tt> </tt>
<a name="L643"></a><tt class="py-lineno">643</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L644"></a><tt class="py-lineno">644</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">==</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L645"></a><tt class="py-lineno">645</tt>  <tt class="py-line">            <tt class="py-comment"># pi(x) * (1 - pi(x)) &lt;= 0.25 = 0.5 * 0.5</tt> </tt>
<a name="L646"></a><tt class="py-lineno">646</tt>  <tt class="py-line">            <tt class="py-name">PWX</tt> <tt class="py-op">=</tt> <tt class="py-number">0.5</tt> <tt class="py-op">*</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">sqrt</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">weights</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt>  <tt class="py-comment"># TODO: CHECK WITH FOUAD</tt> </tt>
<a name="L647"></a><tt class="py-lineno">647</tt>  <tt class="py-line">            <tt class="py-comment"># PW = 0.5 * np.eye(self.X.shape[0]) ## miss np.sqrt(self.W)</tt> </tt>
<a name="L648"></a><tt class="py-lineno">648</tt>  <tt class="py-line">            <tt class="py-comment">#PW = 0.5 * np.sqrt(self.W)</tt> </tt>
<a name="L649"></a><tt class="py-lineno">649</tt>  <tt class="py-line">            <tt class="py-comment">#PWX = np.dot(PW, self.X)</tt> </tt>
<a name="L650"></a><tt class="py-lineno">650</tt>  <tt class="py-line">            <tt class="py-comment"># TODO: Use FastSVD for speedup!</tt> </tt>
<a name="L651"></a><tt class="py-lineno">651</tt>  <tt class="py-line">            <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt><tt class="py-op">.</tt><tt class="py-name">svd</tt><tt class="py-op">(</tt><tt class="py-name">PWX</tt><tt class="py-op">,</tt> <tt class="py-name">full_matrices</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-name">compute_uv</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt> </tt>
<a name="L652"></a><tt class="py-lineno">652</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt>  <tt class="py-comment"># TODO: CHECK</tt> </tt>
<a name="L653"></a><tt class="py-lineno">653</tt>  <tt class="py-line"> </tt>
<a name="L654"></a><tt class="py-lineno">654</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">mean</tt><tt class="py-op">:</tt> </tt>
<a name="L655"></a><tt class="py-lineno">655</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">/=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L656"></a><tt class="py-lineno">656</tt>  <tt class="py-line"> </tt>
<a name="L657"></a><tt class="py-lineno">657</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> <tt class="py-op">+=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">k</tt>  <tt class="py-comment"># TODO: CHECK</tt> </tt>
<a name="L658"></a><tt class="py-lineno">658</tt>  <tt class="py-line"> </tt>
<a name="L659"></a><tt class="py-lineno">659</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_L</tt> </tt>
</div><a name="L660"></a><tt class="py-lineno">660</tt>  <tt class="py-line"> </tt>
<a name="RidgeLogisticRegression.step"></a><div id="RidgeLogisticRegression.step-def"><a name="L661"></a><tt class="py-lineno">661</tt> <a class="py-toggle" href="#" id="RidgeLogisticRegression.step-toggle" onclick="return toggle('RidgeLogisticRegression.step');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.RidgeLogisticRegression-class.html#step">step</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">,</tt> <tt class="py-param">index</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="RidgeLogisticRegression.step-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="RidgeLogisticRegression.step-expanded"><a name="L662"></a><tt class="py-lineno">662</tt>  <tt class="py-line">        <tt class="py-docstring">"""The step size to use in descent methods.</tt> </tt>
<a name="L663"></a><tt class="py-lineno">663</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L664"></a><tt class="py-lineno">664</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L665"></a><tt class="py-lineno">665</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L666"></a><tt class="py-lineno">666</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. The point at which to determine the step size.</tt> </tt>
<a name="L667"></a><tt class="py-lineno">667</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L668"></a><tt class="py-lineno">668</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-79" class="py-name"><a title="parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.L
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.L
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.L
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.L
parsimony.functions.losses.LatentVariableVariance.L
parsimony.functions.losses.LinearFunction.L
parsimony.functions.losses.LinearRegression.L
parsimony.functions.losses.LogisticRegression.L
parsimony.functions.losses.RidgeLogisticRegression.L
parsimony.functions.losses.RidgeRegression.L
parsimony.functions.multiblock.losses.LatentVariableCovariance.L
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.L
parsimony.functions.multiblock.properties.MultiblockLipschitzContinuousGradient.L
parsimony.functions.nesterov.gl.GroupLassoOverlap.L
parsimony.functions.nesterov.grouptv.GroupTotalVariation.L
parsimony.functions.nesterov.l1.L1.L
parsimony.functions.nesterov.tv.TotalVariation.L
parsimony.functions.penalties.L2Squared.L
parsimony.functions.penalties.RidgeSquaredError.L
parsimony.functions.properties.LipschitzContinuousGradient.L
parsimony.functions.properties.NesterovFunction.L" class="py-name" href="#" onclick="return doclink('link-79', 'L', 'link-31');">L</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L669"></a><tt class="py-lineno">669</tt>  <tt class="py-line"> </tt>
<a name="LatentVariableVariance"></a><div id="LatentVariableVariance-def"><a name="L670"></a><tt class="py-lineno">670</tt>  <tt class="py-line"> </tt>
<a name="L671"></a><tt class="py-lineno">671</tt> <a class="py-toggle" href="#" id="LatentVariableVariance-toggle" onclick="return toggle('LatentVariableVariance');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="parsimony.functions.losses.LatentVariableVariance-class.html">LatentVariableVariance</a><tt class="py-op">(</tt><tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">Function</tt><tt class="py-op">,</tt> </tt>
<a name="L672"></a><tt class="py-lineno">672</tt>  <tt class="py-line">                             <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">Gradient</tt><tt class="py-op">,</tt> </tt>
<a name="L673"></a><tt class="py-lineno">673</tt>  <tt class="py-line">                             <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">StepSize</tt><tt class="py-op">,</tt> </tt>
<a name="L674"></a><tt class="py-lineno">674</tt>  <tt class="py-line">                             <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">LipschitzContinuousGradient</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LatentVariableVariance-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="LatentVariableVariance-expanded"><a name="L675"></a><tt class="py-lineno">675</tt>  <tt class="py-line">    <tt class="py-comment"># TODO: Handle mean here?</tt> </tt>
<a name="LatentVariableVariance.__init__"></a><div id="LatentVariableVariance.__init__-def"><a name="L676"></a><tt class="py-lineno">676</tt> <a class="py-toggle" href="#" id="LatentVariableVariance.__init__-toggle" onclick="return toggle('LatentVariableVariance.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LatentVariableVariance-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">X</tt><tt class="py-op">,</tt> <tt class="py-param">unbiased</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LatentVariableVariance.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LatentVariableVariance.__init__-expanded"><a name="L677"></a><tt class="py-lineno">677</tt>  <tt class="py-line"> </tt>
<a name="L678"></a><tt class="py-lineno">678</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt> <tt class="py-op">=</tt> <tt class="py-name">X</tt> </tt>
<a name="L679"></a><tt class="py-lineno">679</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">unbiased</tt><tt class="py-op">:</tt> </tt>
<a name="L680"></a><tt class="py-lineno">680</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_n</tt> <tt class="py-op">=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt> <tt class="py-op">-</tt> <tt class="py-number">1.0</tt><tt class="py-op">)</tt> </tt>
<a name="L681"></a><tt class="py-lineno">681</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L682"></a><tt class="py-lineno">682</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_n</tt> <tt class="py-op">=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt class="py-name">shape</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L683"></a><tt class="py-lineno">683</tt>  <tt class="py-line"> </tt>
<a name="L684"></a><tt class="py-lineno">684</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-80" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.CombinedFunction.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.reset
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.reset
parsimony.functions.losses.LatentVariableVariance.reset
parsimony.functions.losses.LinearFunction.reset
parsimony.functions.losses.LinearRegression.reset
parsimony.functions.losses.LogisticRegression.reset
parsimony.functions.losses.RidgeLogisticRegression.reset
parsimony.functions.losses.RidgeRegression.reset
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.reset
parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset
parsimony.functions.multiblock.losses.LatentVariableCovariance.reset
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.reset
parsimony.functions.nesterov.gl.GroupLassoOverlap.reset
parsimony.functions.nesterov.grouptv.GroupTotalVariation.reset
parsimony.functions.nesterov.l1tv.L1TV.reset
parsimony.functions.nesterov.tv.TotalVariation.reset
parsimony.functions.penalties.LinearVariableConstraint.reset
parsimony.functions.penalties.RGCCAConstraint.reset
parsimony.functions.penalties.RidgeSquaredError.reset
parsimony.functions.penalties.ZeroFunction.reset
parsimony.functions.properties.Function.reset" class="py-name" href="#" onclick="return doclink('link-80', 'reset', 'link-12');">reset</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L685"></a><tt class="py-lineno">685</tt>  <tt class="py-line"> </tt>
<a name="LatentVariableVariance.reset"></a><div id="LatentVariableVariance.reset-def"><a name="L686"></a><tt class="py-lineno">686</tt> <a class="py-toggle" href="#" id="LatentVariableVariance.reset-toggle" onclick="return toggle('LatentVariableVariance.reset');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LatentVariableVariance-class.html#reset">reset</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LatentVariableVariance.reset-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LatentVariableVariance.reset-expanded"><a name="L687"></a><tt class="py-lineno">687</tt>  <tt class="py-line"> </tt>
<a name="L688"></a><tt class="py-lineno">688</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L689"></a><tt class="py-lineno">689</tt>  <tt class="py-line"> </tt>
<a name="LatentVariableVariance.f"></a><div id="LatentVariableVariance.f-def"><a name="L690"></a><tt class="py-lineno">690</tt> <a class="py-toggle" href="#" id="LatentVariableVariance.f-toggle" onclick="return toggle('LatentVariableVariance.f');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LatentVariableVariance-class.html#f">f</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">w</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LatentVariableVariance.f-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LatentVariableVariance.f-expanded"><a name="L691"></a><tt class="py-lineno">691</tt>  <tt class="py-line">        <tt class="py-docstring">"""Function value.</tt> </tt>
<a name="L692"></a><tt class="py-lineno">692</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L693"></a><tt class="py-lineno">693</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L694"></a><tt class="py-lineno">694</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L695"></a><tt class="py-lineno">695</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L696"></a><tt class="py-lineno">696</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L697"></a><tt class="py-lineno">697</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L698"></a><tt class="py-lineno">698</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.algorithms.nipals import FastSVD</tt> </tt>
<a name="L699"></a><tt class="py-lineno">699</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import LatentVariableVariance</tt> </tt>
<a name="L700"></a><tt class="py-lineno">700</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L701"></a><tt class="py-lineno">701</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(1337)</tt> </tt>
<a name="L702"></a><tt class="py-lineno">702</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(50, 150)</tt> </tt>
<a name="L703"></a><tt class="py-lineno">703</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; w = np.random.rand(150, 1)</tt> </tt>
<a name="L704"></a><tt class="py-lineno">704</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; var = LatentVariableVariance(X)</tt> </tt>
<a name="L705"></a><tt class="py-lineno">705</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(var.f(w), 12)</tt> </tt>
<a name="L706"></a><tt class="py-lineno">706</tt>  <tt class="py-line"><tt class="py-docstring">        -1295.854475188615</tt> </tt>
<a name="L707"></a><tt class="py-lineno">707</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(-np.dot(w.T, np.dot(X.T, np.dot(X, w)))[0, 0] / 49.0, 12)</tt> </tt>
<a name="L708"></a><tt class="py-lineno">708</tt>  <tt class="py-line"><tt class="py-docstring">        -1295.854475188615</tt> </tt>
<a name="L709"></a><tt class="py-lineno">709</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L710"></a><tt class="py-lineno">710</tt>  <tt class="py-line">        <tt class="py-name">Xw</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-81" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-81', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">w</tt><tt class="py-op">)</tt> </tt>
<a name="L711"></a><tt class="py-lineno">711</tt>  <tt class="py-line">        <tt class="py-name">wXXw</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-82" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-82', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">Xw</tt><tt class="py-op">.</tt><tt id="link-83" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.T" class="py-name" href="#" onclick="return doclink('link-83', 'T', 'link-19');">T</a></tt><tt class="py-op">,</tt> <tt class="py-name">Xw</tt><tt class="py-op">)</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-number">0</tt><tt class="py-op">]</tt> </tt>
<a name="L712"></a><tt class="py-lineno">712</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">-</tt><tt class="py-name">wXXw</tt> <tt class="py-op">/</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_n</tt> </tt>
</div><a name="L713"></a><tt class="py-lineno">713</tt>  <tt class="py-line"> </tt>
<a name="LatentVariableVariance.grad"></a><div id="LatentVariableVariance.grad-def"><a name="L714"></a><tt class="py-lineno">714</tt> <a class="py-toggle" href="#" id="LatentVariableVariance.grad-toggle" onclick="return toggle('LatentVariableVariance.grad');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LatentVariableVariance-class.html#grad">grad</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">w</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LatentVariableVariance.grad-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LatentVariableVariance.grad-expanded"><a name="L715"></a><tt class="py-lineno">715</tt>  <tt class="py-line">        <tt class="py-docstring">"""Gradient of the function.</tt> </tt>
<a name="L716"></a><tt class="py-lineno">716</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L717"></a><tt class="py-lineno">717</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Gradient".</tt> </tt>
<a name="L718"></a><tt class="py-lineno">718</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L719"></a><tt class="py-lineno">719</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L720"></a><tt class="py-lineno">720</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L721"></a><tt class="py-lineno">721</tt>  <tt class="py-line"><tt class="py-docstring">        w : The point at which to evaluate the gradient.</tt> </tt>
<a name="L722"></a><tt class="py-lineno">722</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L723"></a><tt class="py-lineno">723</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L724"></a><tt class="py-lineno">724</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L725"></a><tt class="py-lineno">725</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L726"></a><tt class="py-lineno">726</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import LatentVariableVariance</tt> </tt>
<a name="L727"></a><tt class="py-lineno">727</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L728"></a><tt class="py-lineno">728</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L729"></a><tt class="py-lineno">729</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(50, 150)</tt> </tt>
<a name="L730"></a><tt class="py-lineno">730</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; var = LatentVariableVariance(X)</tt> </tt>
<a name="L731"></a><tt class="py-lineno">731</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; w = np.random.rand(150, 1)</tt> </tt>
<a name="L732"></a><tt class="py-lineno">732</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.linalg.norm(var.grad(w) - var.approx_grad(w, eps=1e-4)) &lt; 5e-8</tt> </tt>
<a name="L733"></a><tt class="py-lineno">733</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L734"></a><tt class="py-lineno">734</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L735"></a><tt class="py-lineno">735</tt>  <tt class="py-line">        <tt id="link-84" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-84', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">=</tt> <tt class="py-op">-</tt><tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-85" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-85', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">.</tt><tt id="link-86" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.T" class="py-name" href="#" onclick="return doclink('link-86', 'T', 'link-19');">T</a></tt><tt class="py-op">,</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-87" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-87', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">w</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-op">*</tt> <tt class="py-op">(</tt><tt class="py-number">2.0</tt> <tt class="py-op">/</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_n</tt><tt class="py-op">)</tt> </tt>
<a name="L736"></a><tt class="py-lineno">736</tt>  <tt class="py-line"> </tt>
<a name="L737"></a><tt class="py-lineno">737</tt>  <tt class="py-line"><tt class="py-comment">#        approx_grad = utils.approx_grad(f, w, eps=1e-4)</tt> </tt>
<a name="L738"></a><tt class="py-lineno">738</tt>  <tt class="py-line"><tt class="py-comment">#        print "LatentVariableVariance:", maths.norm(grad - approx_grad)</tt> </tt>
<a name="L739"></a><tt class="py-lineno">739</tt>  <tt class="py-line"> </tt>
<a name="L740"></a><tt class="py-lineno">740</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-88" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-88', 'grad', 'link-17');">grad</a></tt> </tt>
</div><a name="L741"></a><tt class="py-lineno">741</tt>  <tt class="py-line"> </tt>
<a name="LatentVariableVariance.L"></a><div id="LatentVariableVariance.L-def"><a name="L742"></a><tt class="py-lineno">742</tt> <a class="py-toggle" href="#" id="LatentVariableVariance.L-toggle" onclick="return toggle('LatentVariableVariance.L');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LatentVariableVariance-class.html#L">L</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LatentVariableVariance.L-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LatentVariableVariance.L-expanded"><a name="L743"></a><tt class="py-lineno">743</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lipschitz constant of the gradient with given index.</tt> </tt>
<a name="L744"></a><tt class="py-lineno">744</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L745"></a><tt class="py-lineno">745</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "LipschitzContinuousGradient".</tt> </tt>
<a name="L746"></a><tt class="py-lineno">746</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L747"></a><tt class="py-lineno">747</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L748"></a><tt class="py-lineno">748</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L749"></a><tt class="py-lineno">749</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L750"></a><tt class="py-lineno">750</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.algorithms.nipals import FastSVD</tt> </tt>
<a name="L751"></a><tt class="py-lineno">751</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import LatentVariableVariance</tt> </tt>
<a name="L752"></a><tt class="py-lineno">752</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L753"></a><tt class="py-lineno">753</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(1337)</tt> </tt>
<a name="L754"></a><tt class="py-lineno">754</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(50, 150)</tt> </tt>
<a name="L755"></a><tt class="py-lineno">755</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; w = np.random.rand(150, 1)</tt> </tt>
<a name="L756"></a><tt class="py-lineno">756</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; var = LatentVariableVariance(X)</tt> </tt>
<a name="L757"></a><tt class="py-lineno">757</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(var.L(), 10)</tt> </tt>
<a name="L758"></a><tt class="py-lineno">758</tt>  <tt class="py-line"><tt class="py-docstring">        47025.0809786841</tt> </tt>
<a name="L759"></a><tt class="py-lineno">759</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; _, S, _ = np.linalg.svd(np.dot(X.T, X))</tt> </tt>
<a name="L760"></a><tt class="py-lineno">760</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(np.max(S) * 49 / 2.0, 10)</tt> </tt>
<a name="L761"></a><tt class="py-lineno">761</tt>  <tt class="py-line"><tt class="py-docstring">        47025.0809786841</tt> </tt>
<a name="L762"></a><tt class="py-lineno">762</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L763"></a><tt class="py-lineno">763</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L764"></a><tt class="py-lineno">764</tt>  <tt class="py-line">            <tt class="py-keyword">from</tt> <tt id="link-89" class="py-name"><a title="parsimony" class="py-name" href="#" onclick="return doclink('link-89', 'parsimony', 'link-1');">parsimony</a></tt><tt class="py-op">.</tt><tt id="link-90" class="py-name"><a title="parsimony.algorithms" class="py-name" href="#" onclick="return doclink('link-90', 'algorithms', 'link-25');">algorithms</a></tt><tt class="py-op">.</tt><tt id="link-91" class="py-name"><a title="parsimony.algorithms.nipals" class="py-name" href="#" onclick="return doclink('link-91', 'nipals', 'link-26');">nipals</a></tt> <tt class="py-keyword">import</tt> <tt id="link-92" class="py-name"><a title="parsimony.algorithms.nipals.FastSVD" class="py-name" href="#" onclick="return doclink('link-92', 'FastSVD', 'link-27');">FastSVD</a></tt> </tt>
<a name="L765"></a><tt class="py-lineno">765</tt>  <tt class="py-line">            <tt class="py-name">v</tt> <tt class="py-op">=</tt> <tt id="link-93" class="py-name"><a title="parsimony.algorithms.nipals.FastSVD" class="py-name" href="#" onclick="return doclink('link-93', 'FastSVD', 'link-27');">FastSVD</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-94" class="py-name"><a title="parsimony.algorithms.bases.ExplicitAlgorithm.run
parsimony.algorithms.bases.ImplicitAlgorithm.run
parsimony.algorithms.cluster.KMeans.run
parsimony.algorithms.coordinate.LassoCoordinateDescent.run
parsimony.algorithms.coordinate.ShootingAlgorithm.run
parsimony.algorithms.gradient.GradientDescent.run
parsimony.algorithms.multiblock.MultiblockCONESTA.run
parsimony.algorithms.multiblock.MultiblockFISTA.run
parsimony.algorithms.nipals.FastSVD.run
parsimony.algorithms.nipals.FastSVDProduct.run
parsimony.algorithms.nipals.FastSparseSVD.run
parsimony.algorithms.nipals.PLSR.run
parsimony.algorithms.nipals.SparsePLSR.run
parsimony.algorithms.primaldual.ExcessiveGapMethod.run
parsimony.algorithms.proximal.ADMM.run
parsimony.algorithms.proximal.CONESTA.run
parsimony.algorithms.proximal.DykstrasProjectionAlgorithm.run
parsimony.algorithms.proximal.DykstrasProximalAlgorithm.run
parsimony.algorithms.proximal.FISTA.run
parsimony.algorithms.proximal.ISTA.run
parsimony.algorithms.proximal.ParallelDykstrasProjectionAlgorithm.run
parsimony.algorithms.proximal.ParallelDykstrasProximalAlgorithm.run
parsimony.algorithms.proximal.StaticCONESTA.run
parsimony.algorithms.utils.BacktrackingLineSearch.run
parsimony.algorithms.utils.Bisection.run
parsimony.algorithms.utils.NewtonRaphson.run" class="py-name" href="#" onclick="return doclink('link-94', 'run', 'link-29');">run</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">max_iter</tt><tt class="py-op">=</tt><tt class="py-number">1000</tt><tt class="py-op">)</tt> </tt>
<a name="L766"></a><tt class="py-lineno">766</tt>  <tt class="py-line">            <tt class="py-name">us</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-95" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-95', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">X</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt><tt class="py-op">)</tt> </tt>
<a name="L767"></a><tt class="py-lineno">767</tt>  <tt class="py-line"> </tt>
<a name="L768"></a><tt class="py-lineno">768</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt class="py-name">linalg</tt><tt class="py-op">.</tt><tt id="link-96" class="py-name" targets="Function parsimony.utils.maths.norm()=parsimony.utils.maths-module.html#norm"><a title="parsimony.utils.maths.norm" class="py-name" href="#" onclick="return doclink('link-96', 'norm', 'link-96');">norm</a></tt><tt class="py-op">(</tt><tt class="py-name">us</tt><tt class="py-op">)</tt> <tt class="py-op">**</tt> <tt class="py-number">2.0</tt> </tt>
<a name="L769"></a><tt class="py-lineno">769</tt>  <tt class="py-line"> </tt>
<a name="L770"></a><tt class="py-lineno">770</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_n</tt> <tt class="py-op">*</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lambda_max</tt> <tt class="py-op">/</tt> <tt class="py-number">2.0</tt> </tt>
</div><a name="L771"></a><tt class="py-lineno">771</tt>  <tt class="py-line"> </tt>
<a name="LatentVariableVariance.step"></a><div id="LatentVariableVariance.step-def"><a name="L772"></a><tt class="py-lineno">772</tt> <a class="py-toggle" href="#" id="LatentVariableVariance.step-toggle" onclick="return toggle('LatentVariableVariance.step');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LatentVariableVariance-class.html#step">step</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">w</tt><tt class="py-op">,</tt> <tt class="py-param">index</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LatentVariableVariance.step-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LatentVariableVariance.step-expanded"><a name="L773"></a><tt class="py-lineno">773</tt>  <tt class="py-line">        <tt class="py-docstring">"""The step size to use in descent methods.</tt> </tt>
<a name="L774"></a><tt class="py-lineno">774</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L775"></a><tt class="py-lineno">775</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L776"></a><tt class="py-lineno">776</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L777"></a><tt class="py-lineno">777</tt>  <tt class="py-line"><tt class="py-docstring">        w : Numpy array. The point at which to determine the step size.</tt> </tt>
<a name="L778"></a><tt class="py-lineno">778</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L779"></a><tt class="py-lineno">779</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L780"></a><tt class="py-lineno">780</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L781"></a><tt class="py-lineno">781</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L782"></a><tt class="py-lineno">782</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.algorithms.nipals import FastSVD</tt> </tt>
<a name="L783"></a><tt class="py-lineno">783</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import LatentVariableVariance</tt> </tt>
<a name="L784"></a><tt class="py-lineno">784</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L785"></a><tt class="py-lineno">785</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L786"></a><tt class="py-lineno">786</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; X = np.random.rand(50, 150)</tt> </tt>
<a name="L787"></a><tt class="py-lineno">787</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; w = np.random.rand(150, 1)</tt> </tt>
<a name="L788"></a><tt class="py-lineno">788</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; var = LatentVariableVariance(X)</tt> </tt>
<a name="L789"></a><tt class="py-lineno">789</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; var.step(w)</tt> </tt>
<a name="L790"></a><tt class="py-lineno">790</tt>  <tt class="py-line"><tt class="py-docstring">        2.1979627581251385e-05</tt> </tt>
<a name="L791"></a><tt class="py-lineno">791</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; _, S, _ = np.linalg.svd(np.dot(X.T, X))</tt> </tt>
<a name="L792"></a><tt class="py-lineno">792</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; round(1.0 / (np.max(S) * 49 / 2.0), 15)</tt> </tt>
<a name="L793"></a><tt class="py-lineno">793</tt>  <tt class="py-line"><tt class="py-docstring">        2.1979627581e-05</tt> </tt>
<a name="L794"></a><tt class="py-lineno">794</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L795"></a><tt class="py-lineno">795</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-number">1.0</tt> <tt class="py-op">/</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-97" class="py-name"><a title="parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.L
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.L
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.L
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.L
parsimony.functions.losses.LatentVariableVariance.L
parsimony.functions.losses.LinearFunction.L
parsimony.functions.losses.LinearRegression.L
parsimony.functions.losses.LogisticRegression.L
parsimony.functions.losses.RidgeLogisticRegression.L
parsimony.functions.losses.RidgeRegression.L
parsimony.functions.multiblock.losses.LatentVariableCovariance.L
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.L
parsimony.functions.multiblock.properties.MultiblockLipschitzContinuousGradient.L
parsimony.functions.nesterov.gl.GroupLassoOverlap.L
parsimony.functions.nesterov.grouptv.GroupTotalVariation.L
parsimony.functions.nesterov.l1.L1.L
parsimony.functions.nesterov.tv.TotalVariation.L
parsimony.functions.penalties.L2Squared.L
parsimony.functions.penalties.RidgeSquaredError.L
parsimony.functions.properties.LipschitzContinuousGradient.L
parsimony.functions.properties.NesterovFunction.L" class="py-name" href="#" onclick="return doclink('link-97', 'L', 'link-31');">L</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L796"></a><tt class="py-lineno">796</tt>  <tt class="py-line"> </tt>
<a name="LinearFunction"></a><div id="LinearFunction-def"><a name="L797"></a><tt class="py-lineno">797</tt>  <tt class="py-line"> </tt>
<a name="L798"></a><tt class="py-lineno">798</tt> <a class="py-toggle" href="#" id="LinearFunction-toggle" onclick="return toggle('LinearFunction');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearFunction-class.html">LinearFunction</a><tt class="py-op">(</tt><tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">CompositeFunction</tt><tt class="py-op">,</tt> </tt>
<a name="L799"></a><tt class="py-lineno">799</tt>  <tt class="py-line">                     <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">Gradient</tt><tt class="py-op">,</tt> </tt>
<a name="L800"></a><tt class="py-lineno">800</tt>  <tt class="py-line">                     <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">LipschitzContinuousGradient</tt><tt class="py-op">,</tt> </tt>
<a name="L801"></a><tt class="py-lineno">801</tt>  <tt class="py-line">                     <tt class="py-base-class">properties</tt><tt class="py-op">.</tt><tt class="py-base-class">StepSize</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearFunction-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="LinearFunction-expanded"><a name="L802"></a><tt class="py-lineno">802</tt>  <tt class="py-line">    <tt class="py-docstring">"""A linear function.</tt> </tt>
<a name="L803"></a><tt class="py-lineno">803</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="LinearFunction.__init__"></a><div id="LinearFunction.__init__-def"><a name="L804"></a><tt class="py-lineno">804</tt> <a class="py-toggle" href="#" id="LinearFunction.__init__-toggle" onclick="return toggle('LinearFunction.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearFunction-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">a</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearFunction.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearFunction.__init__-expanded"><a name="L805"></a><tt class="py-lineno">805</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L806"></a><tt class="py-lineno">806</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L807"></a><tt class="py-lineno">807</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L808"></a><tt class="py-lineno">808</tt>  <tt class="py-line"><tt class="py-docstring">        a : Numpy array (p-by-1). The slope.</tt> </tt>
<a name="L809"></a><tt class="py-lineno">809</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L810"></a><tt class="py-lineno">810</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">a</tt> <tt class="py-op">=</tt> <tt class="py-name">a</tt> </tt>
<a name="L811"></a><tt class="py-lineno">811</tt>  <tt class="py-line"> </tt>
<a name="L812"></a><tt class="py-lineno">812</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-98" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.CombinedFunction.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.reset
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.reset
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.reset
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.reset
parsimony.functions.losses.LatentVariableVariance.reset
parsimony.functions.losses.LinearFunction.reset
parsimony.functions.losses.LinearRegression.reset
parsimony.functions.losses.LogisticRegression.reset
parsimony.functions.losses.RidgeLogisticRegression.reset
parsimony.functions.losses.RidgeRegression.reset
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.reset
parsimony.functions.multiblock.losses.GeneralisedMultiblock.reset
parsimony.functions.multiblock.losses.LatentVariableCovariance.reset
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.reset
parsimony.functions.nesterov.gl.GroupLassoOverlap.reset
parsimony.functions.nesterov.grouptv.GroupTotalVariation.reset
parsimony.functions.nesterov.l1tv.L1TV.reset
parsimony.functions.nesterov.tv.TotalVariation.reset
parsimony.functions.penalties.LinearVariableConstraint.reset
parsimony.functions.penalties.RGCCAConstraint.reset
parsimony.functions.penalties.RidgeSquaredError.reset
parsimony.functions.penalties.ZeroFunction.reset
parsimony.functions.properties.Function.reset" class="py-name" href="#" onclick="return doclink('link-98', 'reset', 'link-12');">reset</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L813"></a><tt class="py-lineno">813</tt>  <tt class="py-line"> </tt>
<a name="LinearFunction.reset"></a><div id="LinearFunction.reset-def"><a name="L814"></a><tt class="py-lineno">814</tt> <a class="py-toggle" href="#" id="LinearFunction.reset-toggle" onclick="return toggle('LinearFunction.reset');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearFunction-class.html#reset">reset</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearFunction.reset-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearFunction.reset-expanded"><a name="L815"></a><tt class="py-lineno">815</tt>  <tt class="py-line">        <tt class="py-docstring">"""Free any cached computations from previous use of this Function.</tt> </tt>
<a name="L816"></a><tt class="py-lineno">816</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L817"></a><tt class="py-lineno">817</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L818"></a><tt class="py-lineno">818</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L819"></a><tt class="py-lineno">819</tt>  <tt class="py-line">        <tt class="py-keyword">pass</tt> </tt>
</div><a name="L820"></a><tt class="py-lineno">820</tt>  <tt class="py-line"> </tt>
<a name="LinearFunction.f"></a><div id="LinearFunction.f-def"><a name="L821"></a><tt class="py-lineno">821</tt> <a class="py-toggle" href="#" id="LinearFunction.f-toggle" onclick="return toggle('LinearFunction.f');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearFunction-class.html#f">f</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearFunction.f-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearFunction.f-expanded"><a name="L822"></a><tt class="py-lineno">822</tt>  <tt class="py-line">        <tt class="py-docstring">"""Function value.</tt> </tt>
<a name="L823"></a><tt class="py-lineno">823</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L824"></a><tt class="py-lineno">824</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Function".</tt> </tt>
<a name="L825"></a><tt class="py-lineno">825</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L826"></a><tt class="py-lineno">826</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L827"></a><tt class="py-lineno">827</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L828"></a><tt class="py-lineno">828</tt>  <tt class="py-line"><tt class="py-docstring">        beta : Numpy array. Regression coefficient vector. The point at which</tt> </tt>
<a name="L829"></a><tt class="py-lineno">829</tt>  <tt class="py-line"><tt class="py-docstring">                to evaluate the function.</tt> </tt>
<a name="L830"></a><tt class="py-lineno">830</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L831"></a><tt class="py-lineno">831</tt>  <tt class="py-line">        <tt id="link-99" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.CombinedFunction.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.f
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.f
parsimony.functions.losses.LatentVariableVariance.f
parsimony.functions.losses.LinearFunction.f
parsimony.functions.losses.LinearRegression.f
parsimony.functions.losses.LogisticRegression.f
parsimony.functions.losses.RidgeLogisticRegression.f
parsimony.functions.losses.RidgeRegression.f
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.f
parsimony.functions.multiblock.losses.GeneralisedMultiblock.f
parsimony.functions.multiblock.losses.LatentVariableCovariance.f
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.f
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.f
parsimony.functions.nesterov.gl.GroupLassoOverlap.f
parsimony.functions.nesterov.grouptv.GroupTotalVariation.f
parsimony.functions.nesterov.l1.L1.f
parsimony.functions.nesterov.l1tv.L1TV.f
parsimony.functions.nesterov.tv.TotalVariation.f
parsimony.functions.penalties.L0.f
parsimony.functions.penalties.L1.f
parsimony.functions.penalties.L1L2Squared.f
parsimony.functions.penalties.L2.f
parsimony.functions.penalties.L2Squared.f
parsimony.functions.penalties.LInf.f
parsimony.functions.penalties.LinearVariableConstraint.f
parsimony.functions.penalties.QuadraticConstraint.f
parsimony.functions.penalties.RGCCAConstraint.f
parsimony.functions.penalties.RidgeSquaredError.f
parsimony.functions.penalties.SufficientDescentCondition.f
parsimony.functions.penalties.ZeroFunction.f
parsimony.functions.properties.CombinedProjectionOperator.f
parsimony.functions.properties.Function.f
parsimony.functions.properties.IndicatorFunction.f
parsimony.functions.properties.SplittableFunction.f" class="py-name" href="#" onclick="return doclink('link-99', 'f', 'link-13');">f</a></tt> <tt class="py-op">=</tt> <tt class="py-name">np</tt><tt class="py-op">.</tt><tt id="link-100" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.dot" class="py-name" href="#" onclick="return doclink('link-100', 'dot', 'link-14');">dot</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">a</tt><tt class="py-op">.</tt><tt id="link-101" class="py-name"><a title="parsimony.utils.linalgs.MultipartArray.T" class="py-name" href="#" onclick="return doclink('link-101', 'T', 'link-19');">T</a></tt><tt class="py-op">,</tt> <tt class="py-name">x</tt><tt class="py-op">)</tt> </tt>
<a name="L832"></a><tt class="py-lineno">832</tt>  <tt class="py-line"> </tt>
<a name="L833"></a><tt class="py-lineno">833</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-102" class="py-name"><a title="parsimony.functions.combinedfunctions.AugmentedLinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.CombinedFunction.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.f
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.f
parsimony.functions.combinedfunctions.LinearRegressionL2SmoothedL1TV.f
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.f
parsimony.functions.losses.LatentVariableVariance.f
parsimony.functions.losses.LinearFunction.f
parsimony.functions.losses.LinearRegression.f
parsimony.functions.losses.LogisticRegression.f
parsimony.functions.losses.RidgeLogisticRegression.f
parsimony.functions.losses.RidgeRegression.f
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.f
parsimony.functions.multiblock.losses.GeneralisedMultiblock.f
parsimony.functions.multiblock.losses.LatentVariableCovariance.f
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.f
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.f
parsimony.functions.nesterov.gl.GroupLassoOverlap.f
parsimony.functions.nesterov.grouptv.GroupTotalVariation.f
parsimony.functions.nesterov.l1.L1.f
parsimony.functions.nesterov.l1tv.L1TV.f
parsimony.functions.nesterov.tv.TotalVariation.f
parsimony.functions.penalties.L0.f
parsimony.functions.penalties.L1.f
parsimony.functions.penalties.L1L2Squared.f
parsimony.functions.penalties.L2.f
parsimony.functions.penalties.L2Squared.f
parsimony.functions.penalties.LInf.f
parsimony.functions.penalties.LinearVariableConstraint.f
parsimony.functions.penalties.QuadraticConstraint.f
parsimony.functions.penalties.RGCCAConstraint.f
parsimony.functions.penalties.RidgeSquaredError.f
parsimony.functions.penalties.SufficientDescentCondition.f
parsimony.functions.penalties.ZeroFunction.f
parsimony.functions.properties.CombinedProjectionOperator.f
parsimony.functions.properties.Function.f
parsimony.functions.properties.IndicatorFunction.f
parsimony.functions.properties.SplittableFunction.f" class="py-name" href="#" onclick="return doclink('link-102', 'f', 'link-13');">f</a></tt> </tt>
</div><a name="L834"></a><tt class="py-lineno">834</tt>  <tt class="py-line"> </tt>
<a name="LinearFunction.grad"></a><div id="LinearFunction.grad-def"><a name="L835"></a><tt class="py-lineno">835</tt> <a class="py-toggle" href="#" id="LinearFunction.grad-toggle" onclick="return toggle('LinearFunction.grad');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearFunction-class.html#grad">grad</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearFunction.grad-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearFunction.grad-expanded"><a name="L836"></a><tt class="py-lineno">836</tt>  <tt class="py-line">        <tt class="py-docstring">"""Gradient of the function at beta.</tt> </tt>
<a name="L837"></a><tt class="py-lineno">837</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L838"></a><tt class="py-lineno">838</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "Gradient".</tt> </tt>
<a name="L839"></a><tt class="py-lineno">839</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L840"></a><tt class="py-lineno">840</tt>  <tt class="py-line"><tt class="py-docstring">        Parameters</tt> </tt>
<a name="L841"></a><tt class="py-lineno">841</tt>  <tt class="py-line"><tt class="py-docstring">        ----------</tt> </tt>
<a name="L842"></a><tt class="py-lineno">842</tt>  <tt class="py-line"><tt class="py-docstring">        x : The point at which to evaluate the gradient.</tt> </tt>
<a name="L843"></a><tt class="py-lineno">843</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L844"></a><tt class="py-lineno">844</tt>  <tt class="py-line">        <tt id="link-103" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-103', 'grad', 'link-17');">grad</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">a</tt> </tt>
<a name="L845"></a><tt class="py-lineno">845</tt>  <tt class="py-line"> </tt>
<a name="L846"></a><tt class="py-lineno">846</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-104" class="py-name"><a title="parsimony.datasets.simulate.grad
parsimony.datasets.simulate.grad.Function.grad
parsimony.datasets.simulate.grad.L1.grad
parsimony.datasets.simulate.grad.L2.grad
parsimony.datasets.simulate.grad.L2Squared.grad
parsimony.datasets.simulate.grad.NesterovFunction.grad
parsimony.datasets.simulate.grad.SmoothedGroupLasso.grad
parsimony.datasets.simulate.grad.SmoothedGroupTotalVariation.grad
parsimony.datasets.simulate.grad.SmoothedL1.grad
parsimony.datasets.simulate.grad.SmoothedTotalVariation.grad
parsimony.datasets.simulate.grad.TotalVariation.grad
parsimony.functions.combinedfunctions.CombinedFunction.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2GL.grad
parsimony.functions.combinedfunctions.LinearRegressionL1L2TV.grad
parsimony.functions.combinedfunctions.PrincipalComponentAnalysisL1TV.grad
parsimony.functions.losses.LatentVariableVariance.grad
parsimony.functions.losses.LinearFunction.grad
parsimony.functions.losses.LinearRegression.grad
parsimony.functions.losses.LogisticRegression.grad
parsimony.functions.losses.RidgeLogisticRegression.grad
parsimony.functions.losses.RidgeRegression.grad
parsimony.functions.multiblock.losses.CombinedMultiblockFunction.grad
parsimony.functions.multiblock.losses.GeneralisedMultiblock.grad
parsimony.functions.multiblock.losses.LatentVariableCovariance.grad
parsimony.functions.multiblock.losses.LatentVariableCovarianceSquared.grad
parsimony.functions.multiblock.losses.MultiblockFunctionWrapper.grad
parsimony.functions.multiblock.properties.MultiblockGradient.grad
parsimony.functions.nesterov.l1.L1.grad
parsimony.functions.penalties.L2Squared.grad
parsimony.functions.penalties.QuadraticConstraint.grad
parsimony.functions.penalties.RGCCAConstraint.grad
parsimony.functions.penalties.RidgeSquaredError.grad
parsimony.functions.penalties.ZeroFunction.grad
parsimony.functions.properties.Gradient.grad
parsimony.functions.properties.NesterovFunction.grad" class="py-name" href="#" onclick="return doclink('link-104', 'grad', 'link-17');">grad</a></tt> </tt>
</div><a name="L847"></a><tt class="py-lineno">847</tt>  <tt class="py-line"> </tt>
<a name="LinearFunction.L"></a><div id="LinearFunction.L-def"><a name="L848"></a><tt class="py-lineno">848</tt> <a class="py-toggle" href="#" id="LinearFunction.L-toggle" onclick="return toggle('LinearFunction.L');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearFunction-class.html#L">L</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearFunction.L-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearFunction.L-expanded"><a name="L849"></a><tt class="py-lineno">849</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lipschitz constant of the gradient.</tt> </tt>
<a name="L850"></a><tt class="py-lineno">850</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L851"></a><tt class="py-lineno">851</tt>  <tt class="py-line"><tt class="py-docstring">        From the interface "LipschitzContinuousGradient".</tt> </tt>
<a name="L852"></a><tt class="py-lineno">852</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L853"></a><tt class="py-lineno">853</tt>  <tt class="py-line"><tt class="py-docstring">        Examples</tt> </tt>
<a name="L854"></a><tt class="py-lineno">854</tt>  <tt class="py-line"><tt class="py-docstring">        --------</tt> </tt>
<a name="L855"></a><tt class="py-lineno">855</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import numpy as np</tt> </tt>
<a name="L856"></a><tt class="py-lineno">856</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from parsimony.functions.losses import LinearFunction</tt> </tt>
<a name="L857"></a><tt class="py-lineno">857</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt;</tt> </tt>
<a name="L858"></a><tt class="py-lineno">858</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; np.random.seed(42)</tt> </tt>
<a name="L859"></a><tt class="py-lineno">859</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; a = np.random.rand(10, 15)</tt> </tt>
<a name="L860"></a><tt class="py-lineno">860</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; f = LinearFunction(a)</tt> </tt>
<a name="L861"></a><tt class="py-lineno">861</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L = f.L()</tt> </tt>
<a name="L862"></a><tt class="py-lineno">862</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L_ = f.approx_L((15, 1), 10)</tt> </tt>
<a name="L863"></a><tt class="py-lineno">863</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L &gt;= L_</tt> </tt>
<a name="L864"></a><tt class="py-lineno">864</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L865"></a><tt class="py-lineno">865</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; L - L_</tt> </tt>
<a name="L866"></a><tt class="py-lineno">866</tt>  <tt class="py-line"><tt class="py-docstring">        0.0</tt> </tt>
<a name="L867"></a><tt class="py-lineno">867</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L868"></a><tt class="py-lineno">868</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-number">0.0</tt> </tt>
</div><a name="L869"></a><tt class="py-lineno">869</tt>  <tt class="py-line"> </tt>
<a name="LinearFunction.step"></a><div id="LinearFunction.step-def"><a name="L870"></a><tt class="py-lineno">870</tt> <a class="py-toggle" href="#" id="LinearFunction.step-toggle" onclick="return toggle('LinearFunction.step');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="parsimony.functions.losses.LinearFunction-class.html#step">step</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">beta</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-param">index</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LinearFunction.step-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="LinearFunction.step-expanded"><a name="L871"></a><tt class="py-lineno">871</tt>  <tt class="py-line">        <tt class="py-docstring">"""The step size to use in descent methods.</tt> </tt>
<a name="L872"></a><tt class="py-lineno">872</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L873"></a><tt class="py-lineno">873</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-number">1.0</tt> </tt>
</div></div><a name="L874"></a><tt class="py-lineno">874</tt>  <tt class="py-line"> </tt>
<a name="L875"></a><tt class="py-lineno">875</tt>  <tt class="py-line"> </tt>
<a name="L876"></a><tt class="py-lineno">876</tt>  <tt class="py-line"><tt class="py-keyword">if</tt> <tt class="py-name">__name__</tt> <tt class="py-op">==</tt> <tt class="py-string">"__main__"</tt><tt class="py-op">:</tt> </tt>
<a name="L877"></a><tt class="py-lineno">877</tt>  <tt class="py-line">    <tt class="py-keyword">import</tt> <tt class="py-name">doctest</tt> </tt>
<a name="L878"></a><tt class="py-lineno">878</tt>  <tt class="py-line">    <tt class="py-name">doctest</tt><tt class="py-op">.</tt><tt class="py-name">testmod</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L879"></a><tt class="py-lineno">879</tt>  <tt class="py-line"> </tt><script type="text/javascript">
<!--
expandto(location.href);
// -->
</script>
</pre>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="parsimony-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

      <th class="navbar" width="100%"></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Mon Apr  6 23:52:13 2015
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
